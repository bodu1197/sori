# MusicGram Backend API
# 200ë§Œ DAU ëŒ€ì‘ í™•ì¥ ê°€ëŠ¥ ì„¤ê³„

from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from datetime import datetime, timedelta, timezone
import os
import json
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# Supabase í´ë¼ì´ì–¸íŠ¸ (ì˜êµ¬ ì €ì¥ì†Œ)
# =============================================================================
supabase_client = None
try:
    from supabase import create_client, Client
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
    if supabase_url and supabase_key:
        supabase_client: Client = create_client(supabase_url, supabase_key)
        logger.info("Supabase connected!")
except ImportError:
    logger.warning("Supabase not installed")
except Exception as e:
    logger.warning(f"Supabase connection failed: {e}")

# Redis ìºì‹œ (ì„ íƒì )
redis_client = None
try:
    import redis
    redis_url = os.getenv("REDIS_URL")
    if redis_url:
        redis_client = redis.from_url(redis_url, decode_responses=True)
        logger.info("Redis connected!")
except ImportError:
    logger.warning("Redis not installed, using in-memory cache")
except Exception as e:
    logger.warning(f"Redis connection failed: {e}")

# ë©”ëª¨ë¦¬ ìºì‹œ (Redis ì—†ì„ ë•Œ í´ë°±)
memory_cache = {}

# YTMusic ì¸ìŠ¤í„´ìŠ¤ (êµ­ê°€ë³„)
ytmusic_instances = {}

# ì „ ì„¸ê³„ êµ­ê°€ë³„ ì–¸ì–´ ë§¤í•‘ (ISO 3166-1 -> ISO 639-1)
COUNTRY_LANGUAGE_MAP = {
    # ì•„ì‹œì•„
    'KR': 'ko', 'JP': 'ja', 'CN': 'zh', 'TW': 'zh', 'HK': 'zh',
    'TH': 'th', 'VN': 'vi', 'ID': 'id', 'MY': 'ms', 'SG': 'en',
    'PH': 'tl', 'IN': 'hi', 'PK': 'ur', 'BD': 'bn', 'NP': 'ne',
    'LK': 'si', 'MM': 'my', 'KH': 'km', 'LA': 'lo', 'MN': 'mn',
    # ì¤‘ë™
    'SA': 'ar', 'AE': 'ar', 'EG': 'ar', 'IQ': 'ar', 'JO': 'ar',
    'KW': 'ar', 'LB': 'ar', 'OM': 'ar', 'QA': 'ar', 'YE': 'ar',
    'IL': 'he', 'IR': 'fa', 'TR': 'tr',
    # ìœ ëŸ½
    'US': 'en', 'GB': 'en', 'AU': 'en', 'NZ': 'en', 'IE': 'en', 'CA': 'en',
    'DE': 'de', 'AT': 'de', 'CH': 'de',
    'FR': 'fr', 'BE': 'fr', 'LU': 'fr',
    'ES': 'es', 'MX': 'es', 'AR': 'es', 'CO': 'es', 'CL': 'es', 'PE': 'es',
    'IT': 'it', 'PT': 'pt', 'BR': 'pt',
    'NL': 'nl', 'PL': 'pl', 'RU': 'ru', 'UA': 'uk', 'CZ': 'cs', 'SK': 'sk',
    'HU': 'hu', 'RO': 'ro', 'BG': 'bg', 'HR': 'hr', 'RS': 'sr', 'SI': 'sl',
    'GR': 'el', 'SE': 'sv', 'NO': 'no', 'DK': 'da', 'FI': 'fi', 'IS': 'is',
    'EE': 'et', 'LV': 'lv', 'LT': 'lt',
    # ì•„í”„ë¦¬ì¹´
    'ZA': 'en', 'NG': 'en', 'KE': 'sw', 'GH': 'en', 'TZ': 'sw',
    'MA': 'ar', 'DZ': 'ar', 'TN': 'ar', 'LY': 'ar',
    'ET': 'am', 'UG': 'en', 'ZW': 'en', 'SN': 'fr', 'CI': 'fr', 'CM': 'fr',
}

def get_ytmusic(country: str = "US"):
    """êµ­ê°€ë³„ YTMusic ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)"""
    from ytmusicapi import YTMusic

    country = country.upper() if country else "US"

    if country not in ytmusic_instances:
        lang = COUNTRY_LANGUAGE_MAP.get(country, 'en')
        ytmusic_instances[country] = YTMusic(language=lang, location=country)

    return ytmusic_instances[country]

def cache_get(key: str):
    """ìºì‹œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    if redis_client:
        data = redis_client.get(key)
        return json.loads(data) if data else None
    return memory_cache.get(key)

def cache_set(key: str, value, ttl: int = 3600):
    """ìºì‹œì— ë°ì´í„° ì €ì¥"""
    if redis_client:
        redis_client.setex(key, ttl, json.dumps(value))
    else:
        memory_cache[key] = value

# =============================================================================
# Supabase DB í—¬í¼ í•¨ìˆ˜
# =============================================================================

def db_save_artist(artist_data: dict) -> str | None:
    """ì•„í‹°ìŠ¤íŠ¸ë¥¼ DBì— ì €ì¥ (upsert)"""
    if not supabase_client:
        return None

    try:
        browse_id = artist_data.get("browseId") or artist_data.get("browse_id")
        if not browse_id:
            return None

        data = {
            "browse_id": browse_id,
            "name": artist_data.get("name") or artist_data.get("artist") or "",
            "thumbnails": json.dumps(artist_data.get("thumbnails") or []),
            "description": artist_data.get("description") or "",
            "subscribers": artist_data.get("subscribers") or "",
            "last_updated": datetime.now(timezone.utc).isoformat()
        }

        result = supabase_client.table("music_artists").upsert(
            data, on_conflict="browse_id"
        ).execute()

        if result.data:
            return result.data[0].get("id")
        return None
    except Exception as e:
        logger.warning(f"DB save artist error: {e}")
        return None

def db_save_album(album_data: dict, artist_id: str = None) -> str | None:
    """ì•¨ë²”ì„ DBì— ì €ì¥ (upsert)"""
    if not supabase_client:
        return None

    try:
        browse_id = album_data.get("browseId") or album_data.get("browse_id")
        if not browse_id:
            return None

        # ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
        artists = album_data.get("artists") or []
        artist_browse_id = None
        if artists and isinstance(artists, list) and len(artists) > 0:
            artist_browse_id = artists[0].get("id") or artists[0].get("browseId")

        data = {
            "browse_id": browse_id,
            "artist_browse_id": artist_browse_id or album_data.get("artist_bid"),
            "title": album_data.get("title") or "",
            "album_type": album_data.get("type") or "Album",
            "year": album_data.get("year") or "",
            "thumbnails": json.dumps(album_data.get("thumbnails") or []),
            "track_count": len(album_data.get("tracks") or []),
            "last_updated": datetime.now(timezone.utc).isoformat()
        }

        if artist_id:
            data["artist_id"] = artist_id

        result = supabase_client.table("music_albums").upsert(
            data, on_conflict="browse_id"
        ).execute()

        if result.data:
            return result.data[0].get("id")
        return None
    except Exception as e:
        logger.warning(f"DB save album error: {e}")
        return None

def db_save_track(track_data: dict, album_id: str = None, artist_id: str = None) -> str | None:
    """íŠ¸ë™ì„ DBì— ì €ì¥ (upsert)"""
    if not supabase_client:
        return None

    try:
        video_id = track_data.get("videoId") or track_data.get("video_id")
        if not video_id:
            return None

        # ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ ì¶”ì¶œ
        artists = track_data.get("artists") or []
        artist_name = ""
        artist_browse_id = None
        if artists and isinstance(artists, list) and len(artists) > 0:
            artist_name = artists[0].get("name") or ""
            artist_browse_id = artists[0].get("id") or artists[0].get("browseId")

        # ì•¨ë²” ì •ë³´ ì¶”ì¶œ
        album = track_data.get("album") or {}
        album_title = album.get("name") or ""
        album_browse_id = album.get("id") or album.get("browseId")

        # ì¬ìƒ ì‹œê°„ íŒŒì‹±
        duration = track_data.get("duration") or ""
        duration_seconds = track_data.get("duration_seconds") or 0
        if duration and not duration_seconds:
            try:
                parts = duration.split(":")
                if len(parts) == 2:
                    duration_seconds = int(parts[0]) * 60 + int(parts[1])
                elif len(parts) == 3:
                    duration_seconds = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
            except:
                pass

        data = {
            "video_id": video_id,
            "artist_browse_id": artist_browse_id or track_data.get("artist_bid"),
            "album_browse_id": album_browse_id,
            "title": track_data.get("title") or "",
            "artist_name": artist_name,
            "album_title": album_title,
            "duration": duration,
            "duration_seconds": duration_seconds,
            "thumbnails": json.dumps(track_data.get("thumbnails") or []),
            "is_explicit": track_data.get("isExplicit") or False
        }

        if album_id:
            data["album_id"] = album_id
        if artist_id:
            data["artist_id"] = artist_id

        result = supabase_client.table("music_tracks").upsert(
            data, on_conflict="video_id"
        ).execute()

        if result.data:
            return result.data[0].get("id")
        return None
    except Exception as e:
        logger.warning(f"DB save track error: {e}")
        return None

def db_get_cached_search_fast(keyword: str, country: str = "US") -> dict | None:
    """ê²€ìƒ‰ ìºì‹œì—ì„œ JSON ë°ì´í„° ì¦‰ì‹œ ì¡°íšŒ (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
    if not supabase_client:
        return None

    try:
        keyword_normalized = keyword.lower()

        # ê²€ìƒ‰ ìºì‹œì—ì„œ result_json ì§ì ‘ ì¡°íšŒ (1íšŒ ì¿¼ë¦¬!)
        result = supabase_client.table("music_search_cache").select(
            "id, result_json, expires_at, search_count"
        ).eq(
            "keyword_normalized", keyword_normalized
        ).eq("country", country).single().execute()

        if not result.data:
            return None

        cache_entry = result.data
        result_json = cache_entry.get("result_json")

        # result_jsonì´ ì—†ìœ¼ë©´ ìºì‹œ ë¯¸ìŠ¤
        if not result_json:
            return None

        # ë§Œë£Œ ì‹œê°„ í™•ì¸ (ìˆëŠ” ê²½ìš°)
        expires_at = cache_entry.get("expires_at")
        if expires_at:
            expire_time = datetime.fromisoformat(expires_at.replace("Z", "+00:00"))
            if datetime.now(timezone.utc) > expire_time:
                logger.info(f"Supabase cache expired for: {keyword}")
                return None

        # ê²€ìƒ‰ ì¹´ìš´íŠ¸ ì¦ê°€ (ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•´ë„ ë¨)
        try:
            supabase_client.table("music_search_cache").update({
                "search_count": cache_entry.get("search_count", 0) + 1,
                "last_searched": datetime.now(timezone.utc).isoformat()
            }).eq("id", cache_entry.get("id")).execute()
        except:
            pass  # ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ

        # JSON ê²°ê³¼ ì§ì ‘ ë°˜í™˜
        result_json["source"] = "supabase"
        logger.info(f"Supabase cache hit: {keyword}")
        return result_json

    except Exception as e:
        logger.warning(f"DB get cached search error: {e}")
        return None


def db_save_cached_search_fast(keyword: str, country: str, result_data: dict, ttl_hours: int = 24):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥ (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
    if not supabase_client:
        return

    try:
        expires_at = (datetime.now(timezone.utc) + timedelta(hours=ttl_hours)).isoformat()

        data = {
            "keyword": keyword,
            "keyword_normalized": keyword.lower(),
            "country": country,
            "result_json": result_data,
            "result_count": len(result_data.get("artists", [])),
            "expires_at": expires_at,
            "last_searched": datetime.now(timezone.utc).isoformat()
        }

        supabase_client.table("music_search_cache").upsert(
            data, on_conflict="keyword_normalized,country"
        ).execute()

        logger.info(f"Supabase cache saved: {keyword}")

    except Exception as e:
        logger.warning(f"DB save cached search error: {e}")

def db_get_existing_video_ids(artist_browse_id: str) -> set:
    """ì•„í‹°ìŠ¤íŠ¸ì˜ ê¸°ì¡´ video_id ëª©ë¡ ì¡°íšŒ (ì¤‘ë³µ ë°©ì§€ìš©)"""
    if not supabase_client or not artist_browse_id:
        return set()

    try:
        result = supabase_client.table("music_tracks").select("video_id").eq(
            "artist_browse_id", artist_browse_id
        ).execute()

        return {r.get("video_id") for r in (result.data or []) if r.get("video_id")}
    except Exception as e:
        logger.warning(f"DB get existing video_ids error: {e}")
        return set()

def db_get_existing_album_ids(artist_browse_id: str) -> set:
    """ì•„í‹°ìŠ¤íŠ¸ì˜ ê¸°ì¡´ album browse_id ëª©ë¡ ì¡°íšŒ (ì¤‘ë³µ ë°©ì§€ìš©)"""
    if not supabase_client or not artist_browse_id:
        return set()

    try:
        result = supabase_client.table("music_albums").select("browse_id").eq(
            "artist_browse_id", artist_browse_id
        ).execute()

        return {r.get("browse_id") for r in (result.data or []) if r.get("browse_id")}
    except Exception as e:
        logger.warning(f"DB get existing album_ids error: {e}")
        return set()

def db_artist_needs_update(browse_id: str, hours: int = 6) -> bool:
    """ì•„í‹°ìŠ¤íŠ¸ê°€ ì—…ë°ì´íŠ¸ í•„ìš”í•œì§€ í™•ì¸ (ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ í›„ Nì‹œê°„ ê²½ê³¼)"""
    if not supabase_client or not browse_id:
        return True

    try:
        result = supabase_client.table("music_artists").select("last_updated").eq(
            "browse_id", browse_id
        ).single().execute()

        if not result.data:
            return True  # ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ í•„ìš”

        last_updated = result.data.get("last_updated")
        if not last_updated:
            return True

        last_time = datetime.fromisoformat(last_updated.replace("Z", "+00:00"))
        return datetime.now(timezone.utc) - last_time > timedelta(hours=hours)
    except Exception as e:
        logger.warning(f"DB artist needs update check error: {e}")
        return True

def db_save_related_artists(main_artist_browse_id: str, related_artists: list):
    """ìœ ì‚¬ ì•„í‹°ìŠ¤íŠ¸ ê´€ê³„ ì €ì¥"""
    if not supabase_client or not related_artists:
        return

    try:
        for related in related_artists:
            related_browse_id = related.get("browseId")
            if not related_browse_id:
                continue

            # ë¨¼ì € ê´€ë ¨ ì•„í‹°ìŠ¤íŠ¸ë„ music_artists í…Œì´ë¸”ì— ì €ì¥
            db_save_artist(related)

            # ê´€ê³„ ì €ì¥
            data = {
                "main_artist_browse_id": main_artist_browse_id,
                "related_artist_browse_id": related_browse_id,
                "relation_type": "similar"
            }

            supabase_client.table("artist_relations").upsert(
                data, on_conflict="main_artist_browse_id,related_artist_browse_id"
            ).execute()

        logger.info(f"Saved {len(related_artists)} related artists for {main_artist_browse_id}")
    except Exception as e:
        logger.warning(f"DB save related artists error: {e}")

def db_save_search_cache(keyword: str, country: str, artist_ids: list):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥"""
    if not supabase_client or not artist_ids:
        return

    try:
        data = {
            "keyword": keyword,
            "keyword_normalized": keyword.lower(),
            "country": country,
            "artist_ids": artist_ids,
            "result_count": len(artist_ids),
            "last_searched": datetime.now(timezone.utc).isoformat()
        }

        supabase_client.table("music_search_cache").upsert(
            data, on_conflict="keyword_normalized,country"
        ).execute()

    except Exception as e:
        logger.warning(f"DB save search cache error: {e}")

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    logger.info("ğŸš€ MusicGram API starting...")
    yield
    # ì¢…ë£Œ ì‹œ
    logger.info("ğŸ‘‹ MusicGram API shutting down...")

# FastAPI ì•±
app = FastAPI(
    title="MusicGram API",
    description="YouTube Music ê¸°ë°˜ ìŒì•… í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì†Œì…œ í”Œë«í¼ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ í—ˆìš©)
allowed_origins = os.getenv("ALLOWED_ORIGINS", "*").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# í—¬ìŠ¤ ì²´í¬
# =============================================================================

@app.get("/")
async def root():
    return {
        "service": "MusicGram API",
        "status": "running",
        "version": "1.0.0"
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "redis": "connected" if redis_client else "not configured",
        "supabase": "connected" if supabase_client else "not configured"
    }

# =============================================================================
# ìŒì•… ê²€ìƒ‰ API
# =============================================================================

@app.get("/api/search")
async def search_music(
    request: Request,
    q: str,
    filter: str = "songs",
    limit: int = 20,
    country: str = None
):
    """ìŒì•… ê²€ìƒ‰"""
    # êµ­ê°€ ê°ì§€ (í—¤ë” ë˜ëŠ” íŒŒë¼ë¯¸í„°)
    if not country:
        country = request.headers.get("CF-IPCountry", "US")
    
    # ìºì‹œ í‚¤
    cache_key = f"search:{country}:{filter}:{q}"
    
    # ìºì‹œ í™•ì¸
    cached = cache_get(cache_key)
    if cached:
        logger.info(f"Cache hit: {cache_key}")
        return {"source": "cache", "results": cached}
    
    # API í˜¸ì¶œ
    try:
        ytmusic = get_ytmusic(country)
        results = ytmusic.search(q, filter=filter, limit=limit)
        
        # ìºì‹œ ì €ì¥ (30ë¶„)
        cache_set(cache_key, results, ttl=1800)
        
        return {"source": "api", "results": results}
    except Exception as e:
        logger.error(f"Search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì°¨íŠ¸ API
# =============================================================================

@app.get("/api/charts")
async def get_charts(request: Request, country: str = None):
    """êµ­ê°€ë³„ ì¸ê¸° ì°¨íŠ¸"""
    if not country:
        country = request.headers.get("CF-IPCountry", "US")
    
    cache_key = f"charts:{country}"
    
    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "charts": cached}
    
    try:
        ytmusic = get_ytmusic(country)
        charts = ytmusic.get_charts(country=country)
        
        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, charts, ttl=3600)
        
        return {"country": country, "source": "api", "charts": charts}
    except Exception as e:
        logger.error(f"Charts error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì‹ ê·œ ì•¨ë²” API
# =============================================================================

@app.get("/api/new-albums")
async def get_new_albums(request: Request, country: str = None):
    """êµ­ê°€ë³„ ì‹ ê·œ ì•¨ë²”"""
    if not country:
        country = request.headers.get("CF-IPCountry", "US")
    
    cache_key = f"new_albums:{country}"
    
    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "albums": cached}
    
    try:
        ytmusic = get_ytmusic(country)
        albums = ytmusic.get_new_albums()
        
        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, albums, ttl=3600)
        
        return {"country": country, "source": "api", "albums": albums}
    except Exception as e:
        logger.error(f"New albums error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# Summary Search API (Sample folder compatible)
# =============================================================================

@app.get("/api/search/summary")
async def search_summary(
    request: Request,
    q: str,
    country: str = None,
    force_refresh: bool = False
):
    """
    Comprehensive search returning all artist data (songs, albums, singles).
    Compatible with sample folder's api_proxy.php?type=summary
    Uses ytmusicapi 1.11.4 with get_artist_albums() for complete discography.

    Data Flow:
    1. Check Redis cache (30min TTL) - fastest
    2. Check Supabase DB (24hr TTL) - permanent storage
    3. Call ytmusicapi and save to both DB and cache
    """
    if not country:
        country = request.headers.get("CF-IPCountry", "US")

    cache_key = f"summary:{country}:{q}"

    # ==========================================================================
    # ìºì‹œ ìˆœì„œ: Supabase (ì˜êµ¬) â†’ Redis (ì„ì‹œ) â†’ ytmusicapi (API)
    # ==========================================================================

    if not force_refresh:
        # 1. Supabase DB í™•ì¸ (ì˜êµ¬ ì €ì¥ì†Œ - ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ê³µìœ )
        db_cached = db_get_cached_search_fast(q, country)
        if db_cached:
            # Redisì—ë„ ìºì‹œ (ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë¹ ë¥´ê²Œ)
            cache_set(cache_key, db_cached, ttl=1800)
            return db_cached

        # 2. Redis/ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸ (ì„ì‹œ ì €ì¥ì†Œ)
        cached = cache_get(cache_key)
        if cached:
            logger.info(f"Redis/memory cache hit: {cache_key}")
            cached["source"] = "redis"
            return cached

    logger.info(f"Fetching from ytmusicapi: {q}")

    try:
        ytmusic = get_ytmusic(country)

        # 1. Search for artists (with error handling)
        # Note: filter="artists" sometimes returns empty, so use general search as fallback
        artists_search = []
        try:
            artists_search = ytmusic.search(q, filter="artists", limit=5) or []
            # Fallback: if filtered search returns empty, use general search
            if not artists_search:
                general_results = ytmusic.search(q, limit=50) or []
                artists_search = [r for r in general_results if r.get("resultType") == "artist"][:5]
        except Exception as e:
            logger.warning(f"Artist search error: {e}")

        # 2. Also search for songs directly (for song title searches)
        # This helps when user searches for a song title like "Dynamite"
        songs_search = []
        try:
            direct_song_results = ytmusic.search(q, filter="songs", limit=20) or []
            for song in direct_song_results:
                if isinstance(song, dict) and song.get("videoId"):
                    song_copy = dict(song)
                    song_copy["resultType"] = "song"
                    song_copy["from_direct_search"] = True  # Mark as from direct search
                    songs_search.append(song_copy)
        except Exception as e:
            logger.warning(f"Song search error: {e}")

        # 3. Skip general albums search - we'll get albums from artist page only
        albums_search = []  # Will be populated from artist page below

        # 4. For each artist, get complete discography
        artists_data = []
        albums_data = []

        for artist in artists_search[:2]:  # Top 2 artists to reduce load
            if not isinstance(artist, dict):
                continue
            artist_id = artist.get("browseId")
            if not artist_id:
                continue
            try:
                artist_info = ytmusic.get_artist(artist_id)
                if not artist_info or not isinstance(artist_info, dict):
                    continue

                # Extract artist details
                # Use search result thumbnails (square) instead of get_artist thumbnails (banner)
                search_thumbnails = artist.get("thumbnails") or []
                artist_entry = {
                    "artist": artist_info.get("name") or artist.get("artist") or "",
                    "browseId": artist_id,
                    "thumbnails": search_thumbnails if search_thumbnails else artist_info.get("thumbnails") or [],
                    "description": artist_info.get("description") or "",
                    "subscribers": artist_info.get("subscribers") or ""
                }
                artists_data.append(artist_entry)

                # Extract songs from artist page (only this artist's songs)
                songs_section = artist_info.get("songs")
                if songs_section and isinstance(songs_section, dict):
                    song_results = songs_section.get("results") or []
                    for song in song_results:
                        if isinstance(song, dict):
                            song_copy = dict(song)
                            song_copy["artist_bid"] = artist_id
                            song_copy["resultType"] = "song"
                            songs_search.append(song_copy)  # Add to songs list

                # Get albums list WITHOUT fetching each album's details (FAST!)
                # Album details can be fetched on-demand when user clicks an album
                albums_section = artist_info.get("albums")
                if albums_section and isinstance(albums_section, dict):
                    # First try get_artist_albums for complete list
                    params = albums_section.get("params")
                    browse_id = albums_section.get("browseId")
                    album_list = []

                    if params and browse_id:
                        try:
                            album_list = ytmusic.get_artist_albums(browse_id, params) or []
                        except Exception as e:
                            logger.warning(f"get_artist_albums error: {e}")

                    # Fallback to results from artist page
                    if not album_list:
                        album_list = albums_section.get("results") or []

                    # Add albums WITHOUT fetching details (no get_album calls!)
                    for album in album_list[:15]:  # Limit to 15 albums
                        if not isinstance(album, dict):
                            continue
                        album_id = album.get("browseId")
                        if not album_id:
                            continue

                        album_entry = {
                            "title": album.get("title") or "",
                            "browseId": album_id,
                            "artists": [{"name": artist_entry.get("artist"), "id": artist_id}],
                            "thumbnails": album.get("thumbnails") or [],
                            "year": album.get("year") or "",
                            "type": album.get("type") or "Album",
                            "artist_bid": artist_id,
                            "tracks": []  # Empty - fetch on demand
                        }
                        albums_data.append(album_entry)

                # Get related artists from artist page
                related_section = artist_info.get("related")
                if related_section and isinstance(related_section, dict):
                    related_results = related_section.get("results") or []
                    for related_artist in related_results[:10]:  # Limit to 10 related artists
                        if isinstance(related_artist, dict):
                            related_entry = {
                                "browseId": related_artist.get("browseId") or "",
                                "artist": related_artist.get("title") or related_artist.get("name") or "",
                                "name": related_artist.get("title") or related_artist.get("name") or "",
                                "subscribers": related_artist.get("subscribers") or "",
                                "thumbnails": related_artist.get("thumbnails") or []
                            }
                            # Add to artist_entry's related list
                            if "related" not in artist_entry:
                                artist_entry["related"] = []
                            artist_entry["related"].append(related_entry)

                # Get singles list WITHOUT fetching details (FAST!)
                singles_section = artist_info.get("singles")
                if singles_section and isinstance(singles_section, dict):
                    params = singles_section.get("params")
                    browse_id = singles_section.get("browseId")
                    singles_list = []

                    if params and browse_id:
                        try:
                            singles_list = ytmusic.get_artist_albums(browse_id, params) or []
                        except Exception as e:
                            logger.warning(f"get_artist_albums for singles error: {e}")

                    if not singles_list:
                        singles_list = singles_section.get("results") or []

                    # Add singles WITHOUT fetching details
                    for single in singles_list[:10]:  # Limit to 10 singles
                        if not isinstance(single, dict):
                            continue
                        single_id = single.get("browseId")
                        if not single_id:
                            continue

                        single_entry = {
                            "title": single.get("title") or "",
                            "browseId": single_id,
                            "artists": [{"name": artist_entry.get("artist"), "id": artist_id}],
                            "thumbnails": single.get("thumbnails") or [],
                            "year": single.get("year") or "",
                            "type": "Single",
                            "artist_bid": artist_id,
                            "tracks": []  # Empty - fetch on demand
                        }
                        albums_data.append(single_entry)

            except Exception as artist_err:
                logger.warning(f"Artist fetch error for {artist_id}: {artist_err}")

        result = {
            "keyword": q,
            "country": country,
            "artists": artists_data,
            "songs": songs_search,
            "albums": albums_search,
            "albums2": albums_data,  # Artist discography (like sample folder)
            "source": "ytmusicapi"
        }

        # =======================================================================
        # ìºì‹œ ì €ì¥ (2ë‹¨ê³„)
        # =======================================================================

        # 1. Redis/ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥ (30ë¶„ TTL)
        cache_set(cache_key, result, ttl=1800)

        # 2. Supabaseì— JSON ê²°ê³¼ ì €ì¥ (24ì‹œê°„ TTL) - ë¹ ë¥¸ ì¡°íšŒìš©
        db_save_cached_search_fast(q, country, result, ttl_hours=24)

        # 3. (ì„ íƒ) ë©”íƒ€ë°ì´í„° í…Œì´ë¸”ì— ì €ì¥ - ì¥ê¸° ë³´ê´€ìš© (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ê¶Œì¥)
        # í˜„ì¬ëŠ” ë¹„í™œì„±í™” - ê²€ìƒ‰ ì†ë„ ìš°ì„ 
        # TODO: ë³„ë„ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì´ë™
        """
        if supabase_client and artists_data:
            try:
                for artist in artists_data:
                    db_save_artist(artist)
                    # ... ì•¨ë²”, íŠ¸ë™ ì €ì¥ ë¡œì§
            except Exception as db_err:
                logger.warning(f"DB metadata save error: {db_err}")
        """

        return result

    except Exception as e:
        logger.error(f"Summary search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ API
# =============================================================================

@app.get("/api/artist/{artist_id}")
async def get_artist(artist_id: str, country: str = "US"):
    """ì•„í‹°ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´"""
    cache_key = f"artist:{artist_id}:{country}"

    cached = cache_get(cache_key)
    if cached:
        return {"source": "cache", "artist": cached}

    try:
        ytmusic = get_ytmusic(country)
        artist = ytmusic.get_artist(artist_id)

        # 6ì‹œê°„ ìºì‹œ
        cache_set(cache_key, artist, ttl=21600)

        return {"source": "api", "artist": artist}
    except Exception as e:
        logger.error(f"Artist error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì•¨ë²” ì •ë³´ API
# =============================================================================

@app.get("/api/album/{album_id}")
async def get_album(album_id: str, country: str = "US"):
    """ì•¨ë²” ìƒì„¸ ì •ë³´"""
    cache_key = f"album:{album_id}:{country}"

    cached = cache_get(cache_key)
    if cached:
        return {"source": "cache", "album": cached}

    try:
        ytmusic = get_ytmusic(country)
        album = ytmusic.get_album(album_id)

        # 6ì‹œê°„ ìºì‹œ
        cache_set(cache_key, album, ttl=21600)

        return {"source": "api", "album": album}
    except Exception as e:
        logger.error(f"Album error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)
