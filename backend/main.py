# MusicGram Backend API
# 200ë§Œ DAU ëŒ€ì‘ í™•ì¥ ê°€ëŠ¥ ì„¤ê³„

from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from datetime import datetime, timedelta, timezone
import os
import json
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
from ai_agent import generate_artist_persona, chat_with_artist, generate_artist_post, generate_artist_comment, generate_artist_dm
import random

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# Supabase í´ë¼ì´ì–¸íŠ¸ (ì˜êµ¬ ì €ì¥ì†Œ)
# =============================================================================
supabase_client = None
try:
    from supabase import create_client, Client
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
    if supabase_url and supabase_key:
        supabase_client: Client = create_client(supabase_url, supabase_key)
        logger.info("Supabase connected!")
except ImportError:
    logger.warning("Supabase not installed")
except Exception as e:
    logger.warning(f"Supabase connection failed: {e}")

# Redis ì œê±° - Supabase DBë§Œ ì‚¬ìš©
redis_client = None  # ì‚¬ìš© ì•ˆí•¨

# YTMusic ì¸ìŠ¤í„´ìŠ¤ (êµ­ê°€ë³„)
ytmusic_instances = {}

# YouTube Music API ì§€ì› ì–¸ì–´: en, pt, ru, zh_CN, de, ja, ar, cs, tr, es, ur, it, hi, ko, nl, zh_TW, fr
# ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ëŠ” ì˜ì–´(en)ë¡œ ëŒ€ì²´
COUNTRY_LANGUAGE_MAP = {
    # ì•„ì‹œì•„
    'KR': 'ko', 'JP': 'ja', 'CN': 'zh_CN', 'TW': 'zh_TW', 'HK': 'zh_TW',
    'TH': 'en', 'VN': 'en', 'ID': 'en', 'MY': 'en', 'SG': 'en',
    'PH': 'en', 'IN': 'hi', 'PK': 'ur', 'BD': 'en', 'NP': 'en',
    'LK': 'en', 'MM': 'en', 'KH': 'en', 'LA': 'en', 'MN': 'en',
    # ì¤‘ë™
    'SA': 'ar', 'AE': 'ar', 'EG': 'ar', 'IQ': 'ar', 'JO': 'ar',
    'KW': 'ar', 'LB': 'ar', 'OM': 'ar', 'QA': 'ar', 'YE': 'ar',
    'IL': 'en', 'IR': 'en', 'TR': 'tr',
    # ìœ ëŸ½
    'US': 'en', 'GB': 'en', 'AU': 'en', 'NZ': 'en', 'IE': 'en', 'CA': 'en',
    'DE': 'de', 'AT': 'de', 'CH': 'de',
    'FR': 'fr', 'BE': 'fr', 'LU': 'fr',
    'ES': 'es', 'MX': 'es', 'AR': 'es', 'CO': 'es', 'CL': 'es', 'PE': 'es',
    'IT': 'it', 'PT': 'pt', 'BR': 'pt',
    'NL': 'nl', 'PL': 'en', 'RU': 'ru', 'UA': 'en', 'CZ': 'cs', 'SK': 'en',
    'HU': 'en', 'RO': 'en', 'BG': 'en', 'HR': 'en', 'RS': 'en', 'SI': 'en',
    'GR': 'en', 'SE': 'en', 'NO': 'en', 'DK': 'en', 'FI': 'en', 'IS': 'en',
    'EE': 'en', 'LV': 'en', 'LT': 'en',
    # ì•„í”„ë¦¬ì¹´
    'ZA': 'en', 'NG': 'en', 'KE': 'en', 'GH': 'en', 'TZ': 'en',
    'MA': 'ar', 'DZ': 'ar', 'TN': 'ar', 'LY': 'ar',
    'ET': 'en', 'UG': 'en', 'ZW': 'en', 'SN': 'fr', 'CI': 'fr', 'CM': 'fr',
}

def get_ytmusic(country: str = "US"):
    """êµ­ê°€ë³„ YTMusic ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)"""
    from ytmusicapi import YTMusic

    country = country.upper() if country else "US"

    if country not in ytmusic_instances:
        lang = COUNTRY_LANGUAGE_MAP.get(country, 'en')
        ytmusic_instances[country] = YTMusic(language=lang, location=country)

    return ytmusic_instances[country]

def cache_get(key: str):
    """ìºì‹œ ë¹„í™œì„±í™” - í•­ìƒ None ë°˜í™˜"""
    del key  # Intentionally unused - caching disabled
    return None

def cache_set(key: str, value, ttl: int = 3600):
    """ìºì‹œ ë¹„í™œì„±í™” - ì•„ë¬´ ë™ì‘ ì•ˆí•¨"""
    del key, value, ttl  # Intentionally unused - caching disabled

# =============================================================================
# Helper: Run sync code in thread
# =============================================================================

async def run_in_thread(func, *args, **kwargs):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda: func(*args, **kwargs))

# Error message constants
ERROR_ACCESS_TOKEN_REQUIRED = "access_token required"

# =============================================================================
# Supabase DB í—¬í¼ í•¨ìˆ˜
# =============================================================================

def db_save_artist(artist_data: dict) -> str | None:
    """ì•„í‹°ìŠ¤íŠ¸ë¥¼ DBì— ì €ì¥ (upsert) + ìë™ ê°€ìƒíšŒì› ìƒì„±"""
    if not supabase_client:
        return None

    try:
        browse_id = artist_data.get("browseId") or artist_data.get("browse_id")
        if not browse_id:
            return None

        thumbnails = artist_data.get("thumbnails") or []
        artist_name = artist_data.get("name") or artist_data.get("artist") or ""
        thumbnail_url = get_best_thumbnail(thumbnails)

        data = {
            "browse_id": browse_id,
            "name": artist_name,
            "thumbnails": json.dumps(thumbnails),
            "thumbnail_url": thumbnail_url,
            "description": artist_data.get("description") or "",
            "subscribers": artist_data.get("subscribers") or "",
            "last_updated": datetime.now(timezone.utc).isoformat()
        }

        result = supabase_client.table("music_artists").upsert(
            data, on_conflict="browse_id"
        ).execute()

        # ìë™ ê°€ìƒíšŒì› ìƒì„± (ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ)
        if result.data:
            try:
                # Check if virtual member already exists
                existing = supabase_client.table("profiles").select("id").eq("artist_browse_id", browse_id).execute()
                if not existing.data or len(existing.data) == 0:
                    # Create virtual member in background
                    create_virtual_member_sync(browse_id, artist_name, thumbnail_url)
            except Exception as vm_error:
                logger.warning(f"Virtual member auto-creation skipped: {vm_error}")

        if result.data:
            return result.data[0].get("id")
        return None
    except Exception as e:
        logger.warning(f"DB save artist error: {e}")
        return None


def create_virtual_member_sync(browse_id: str, artist_name: str, thumbnail_url: str) -> str | None:
    """Synchronously create a virtual member for an artist"""
    if not supabase_client:
        return None

    try:
        import uuid
        import requests

        virtual_email = f"{browse_id}@sori.virtual"
        random_password = str(uuid.uuid4())

        supabase_url = os.getenv("SUPABASE_URL")
        service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

        if not supabase_url or not service_key:
            logger.warning("Supabase credentials not configured for virtual member creation")
            return None

        # Create auth user
        create_user_response = requests.post(
            f"{supabase_url}/auth/v1/admin/users",
            headers={
                "apikey": service_key,
                "Authorization": f"Bearer {service_key}",
                "Content-Type": "application/json"
            },
            json={
                "email": virtual_email,
                "password": random_password,
                "email_confirm": True,
                "user_metadata": {
                    "full_name": artist_name,
                    "avatar_url": thumbnail_url,
                    "member_type": "artist",
                    "artist_browse_id": browse_id
                }
            },
            timeout=10
        )

        if create_user_response.status_code not in [200, 201]:
            return None

        user_data = create_user_response.json()
        user_id = user_data.get("id")

        # Generate username (ensure minimum 3 chars)
        base_username = artist_name.lower().replace(" ", "").replace(".", "").replace("-", "")[:20]
        if len(base_username) < 3:
            base_username = f"{base_username}_official"

        # Update profiles
        supabase_client.table("profiles").upsert({
            "id": user_id,
            "username": base_username,
            "full_name": artist_name,
            "avatar_url": thumbnail_url,
            "member_type": "artist",
            "artist_browse_id": browse_id,
            "is_verified": True,
            "bio": f"Official SORI profile for {artist_name}"
        }).execute()

        logger.info(f"Virtual member auto-created: {artist_name} ({browse_id})")
        return user_id

    except Exception as e:
        logger.warning(f"Virtual member sync creation failed: {e}")
        return None

def db_save_album(album_data: dict, artist_id: str = None) -> str | None:
    """ì•¨ë²”ì„ DBì— ì €ì¥ (upsert)"""
    if not supabase_client:
        return None

    try:
        browse_id = album_data.get("browseId") or album_data.get("browse_id")
        if not browse_id:
            return None

        # ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
        artists = album_data.get("artists") or []
        artist_browse_id = None
        if artists and isinstance(artists, list) and len(artists) > 0:
            artist_browse_id = artists[0].get("id") or artists[0].get("browseId")

        data = {
            "browse_id": browse_id,
            "artist_browse_id": artist_browse_id or album_data.get("artist_bid"),
            "title": album_data.get("title") or "",
            "album_type": album_data.get("type") or "Album",
            "year": album_data.get("year") or "",
            "thumbnails": json.dumps(album_data.get("thumbnails") or []),
            "track_count": len(album_data.get("tracks") or []),
            "last_updated": datetime.now(timezone.utc).isoformat()
        }

        if artist_id:
            data["artist_id"] = artist_id

        result = supabase_client.table("music_albums").upsert(
            data, on_conflict="browse_id"
        ).execute()

        if result.data:
            return result.data[0].get("id")
        return None
    except Exception as e:
        logger.warning(f"DB save album error: {e}")
        return None

def db_save_track(track_data: dict, album_id: str = None, artist_id: str = None) -> str | None:
    """íŠ¸ë™ì„ DBì— ì €ì¥ (upsert)"""
    if not supabase_client:
        return None

    try:
        video_id = track_data.get("videoId") or track_data.get("video_id")
        if not video_id:
            return None

        # ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ ì¶”ì¶œ
        artists = track_data.get("artists") or []
        artist_name = ""
        artist_browse_id = None
        if artists and isinstance(artists, list) and len(artists) > 0:
            artist_name = artists[0].get("name") or ""
            artist_browse_id = artists[0].get("id") or artists[0].get("browseId")

        # ì•¨ë²” ì •ë³´ ì¶”ì¶œ
        album = track_data.get("album") or {}
        album_title = album.get("name") or ""
        album_browse_id = album.get("id") or album.get("browseId")

        # ì¬ìƒ ì‹œê°„ íŒŒì‹±
        duration = track_data.get("duration") or ""
        duration_seconds = track_data.get("duration_seconds") or 0
        if duration and not duration_seconds:
            try:
                parts = duration.split(":")
                if len(parts) == 2:
                    duration_seconds = int(parts[0]) * 60 + int(parts[1])
                elif len(parts) == 3:
                    duration_seconds = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
            except ValueError:
                pass

        data = {
            "video_id": video_id,
            "artist_browse_id": artist_browse_id or track_data.get("artist_bid"),
            "album_browse_id": album_browse_id,
            "title": track_data.get("title") or "",
            "artist_name": artist_name,
            "album_title": album_title,
            "duration": duration,
            "duration_seconds": duration_seconds,
            "thumbnails": json.dumps(track_data.get("thumbnails") or []),
            "is_explicit": track_data.get("isExplicit") or False
        }

        if album_id:
            data["album_id"] = album_id
        if artist_id:
            data["artist_id"] = artist_id

        result = supabase_client.table("music_tracks").upsert(
            data, on_conflict="video_id"
        ).execute()

        if result.data:
            return result.data[0].get("id")
        return None
    except Exception as e:
        logger.warning(f"DB save track error: {e}")
        return None

# =============================================================================
# ì •ê·œí™”ëœ DB í•¨ìˆ˜ë“¤ (ìƒˆë¡œìš´ í…Œì´ë¸” êµ¬ì¡°)
# =============================================================================

def db_get_artist_by_browse_id(browse_id: str) -> dict | None:
    """ì•„í‹°ìŠ¤íŠ¸ë¥¼ browse_idë¡œ ì¡°íšŒ"""
    if not supabase_client or not browse_id:
        return None
    try:
        result = supabase_client.table("music_artists").select("*").eq(
            "browse_id", browse_id
        ).single().execute()
        return result.data
    except Exception as e:
        logger.warning(f"DB get artist error: {e}")
        return None

def db_check_artist_needs_sync(browse_id: str, days: int = 7) -> bool:
    """ì•„í‹°ìŠ¤íŠ¸ê°€ ë™ê¸°í™” í•„ìš”í•œì§€ í™•ì¸ (last_synced_atì´ Nì¼ ì´ˆê³¼)"""
    if not supabase_client or not browse_id:
        return True
    try:
        result = supabase_client.table("music_artists").select(
            "last_synced_at"
        ).eq("browse_id", browse_id).single().execute()

        if not result.data or not result.data.get("last_synced_at"):
            return True

        last_synced = result.data.get("last_synced_at")
        last_time = datetime.fromisoformat(last_synced.replace("Z", "+00:00"))
        return datetime.now(timezone.utc) - last_time > timedelta(days=days)
    except Exception:
        return True

def db_save_artist_full(artist_data: dict) -> bool:
    """ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì •ê·œí™” í…Œì´ë¸”ì— ì €ì¥ (upsert)"""
    if not supabase_client or not artist_data:
        return False
    try:
        browse_id = artist_data.get("browseId")
        if not browse_id:
            return False

        # ì¸ê¸°ê³¡ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë§Œ ì¶”ì¶œ (YouTube IFrame APIìš©)
        songs_playlist_id = artist_data.get("songsPlaylistId")

        data = {
            "browse_id": browse_id,
            "name": artist_data.get("artist") or artist_data.get("name") or "",
            "thumbnail_url": get_best_thumbnail(artist_data.get("thumbnails", [])),
            "subscribers": artist_data.get("subscribers") or "",
            "description": artist_data.get("description") or "",
            "top_songs_json": artist_data.get("topSongs") or [],
            "related_artists_json": artist_data.get("related") or [],
            "songs_playlist_id": songs_playlist_id,
            "updated_at": datetime.now(timezone.utc).isoformat(),
            "last_synced_at": datetime.now(timezone.utc).isoformat()
        }

        supabase_client.table("music_artists").upsert(
            data, on_conflict="browse_id"
        ).execute()

        logger.info(f"Artist saved: {data['name']} ({browse_id}) playlist: {songs_playlist_id}")

        # ìë™ ê°€ìƒíšŒì› ìƒì„± (ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ)
        try:
            existing = supabase_client.table("profiles").select("id").eq("artist_browse_id", browse_id).execute()
            if not existing.data or len(existing.data) == 0:
                create_virtual_member_sync(browse_id, data['name'], data['thumbnail_url'])
        except Exception as vm_error:
            logger.warning(f"Virtual member auto-creation skipped: {vm_error}")

        return True
    except Exception as e:
        logger.warning(f"DB save artist error: {e}")
        return False

def db_save_album(album_data: dict, artist_browse_id: str) -> bool:
    """ì•¨ë²” ì •ë³´ ì €ì¥"""
    if not supabase_client or not album_data or not artist_browse_id:
        return False
    try:
        browse_id = album_data.get("browseId")
        if not browse_id:
            return False

        data = {
            "browse_id": browse_id,
            "artist_browse_id": artist_browse_id,
            "title": album_data.get("title") or "",
            "type": album_data.get("type") or "Album",
            "year": album_data.get("year") or "",
            "thumbnail_url": get_best_thumbnail(album_data.get("thumbnails", [])),
            "track_count": len(album_data.get("tracks", []))
        }

        supabase_client.table("music_albums").upsert(
            data, on_conflict="browse_id"
        ).execute()
        return True
    except Exception as e:
        logger.warning(f"DB save album error: {e}")
        return False

def db_save_track(track_data: dict, album_browse_id: str, artist_browse_id: str, track_number: int = 0) -> bool:
    """íŠ¸ë™ ì •ë³´ ì €ì¥"""
    if not supabase_client or not track_data or not artist_browse_id:
        return False
    try:
        video_id = track_data.get("videoId")
        if not video_id:
            return False

        # durationì„ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
        duration = track_data.get("duration") or ""
        duration_seconds = 0
        if duration:
            parts = duration.split(":")
            if len(parts) == 2:
                duration_seconds = int(parts[0]) * 60 + int(parts[1])
            elif len(parts) == 3:
                duration_seconds = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])

        data = {
            "video_id": video_id,
            "album_browse_id": album_browse_id,
            "artist_browse_id": artist_browse_id,
            "title": track_data.get("title") or "",
            "duration": duration,
            "duration_seconds": duration_seconds,
            "track_number": track_number,
            "thumbnail_url": get_best_thumbnail(track_data.get("thumbnails", [])),
            "is_explicit": track_data.get("isExplicit", False)
        }

        supabase_client.table("music_tracks").upsert(
            data, on_conflict="video_id"
        ).execute()
        return True
    except Exception as e:
        logger.warning(f"DB save track error: {e}")
        return False

def db_save_search_keyword(keyword: str, country: str, artist_browse_id: str):
    """ê²€ìƒ‰ì–´-ì•„í‹°ìŠ¤íŠ¸ ë§¤í•‘ ì €ì¥"""
    if not supabase_client or not keyword or not artist_browse_id:
        return
    try:
        data = {
            "keyword": keyword,
            "keyword_normalized": keyword.lower(),
            "country": country,
            "artist_browse_id": artist_browse_id,
            "search_count": 1,
            "last_searched_at": datetime.now(timezone.utc).isoformat()
        }

        supabase_client.table("search_keywords").upsert(
            data, on_conflict="keyword_normalized,country,artist_browse_id"
        ).execute()
    except Exception as e:
        logger.warning(f"DB save search keyword error: {e}")

def db_increment_search_count(keyword: str, country: str):
    """ê²€ìƒ‰ íšŸìˆ˜ ì¦ê°€"""
    if not supabase_client:
        return
    try:
        keyword_normalized = keyword.lower()
        supabase_client.rpc("increment_search_count", {
            "p_keyword": keyword_normalized,
            "p_country": country
        }).execute()
    except Exception:
        pass  # ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ

def db_get_artists_by_keyword(keyword: str, country: str) -> list:
    """ê²€ìƒ‰ì–´ë¡œ ë§¤í•‘ëœ ì•„í‹°ìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    if not supabase_client:
        return []
    try:
        keyword_normalized = keyword.lower()

        # search_keywordsì—ì„œ artist_browse_id ëª©ë¡ ì¡°íšŒ
        result = supabase_client.table("search_keywords").select(
            "artist_browse_id"
        ).eq("keyword_normalized", keyword_normalized).eq("country", country).execute()

        if not result.data:
            return []

        artist_browse_ids = [r["artist_browse_id"] for r in result.data]
        return artist_browse_ids
    except Exception as e:
        logger.warning(f"DB get artists by keyword error: {e}")
        return []

def db_get_full_artist_data(browse_id: str) -> dict | None:
    """ì•„í‹°ìŠ¤íŠ¸ì˜ ì „ì²´ ë°ì´í„° ì¡°íšŒ (ì•¨ë²”, íŠ¸ë™ í¬í•¨)"""
    if not supabase_client or not browse_id:
        return None
    try:
        # ì•„í‹°ìŠ¤íŠ¸ ê¸°ë³¸ ì •ë³´
        artist_result = supabase_client.table("music_artists").select("*").eq(
            "browse_id", browse_id
        ).single().execute()

        if not artist_result.data:
            return None

        artist = artist_result.data

        # ì•¨ë²” ëª©ë¡
        albums_result = supabase_client.table("music_albums").select("*").eq(
            "artist_browse_id", browse_id
        ).order("year", desc=True).execute()

        albums = albums_result.data or []

        # ì „ì²´ íŠ¸ë™ ëª©ë¡
        tracks_result = supabase_client.table("music_tracks").select("*").eq(
            "artist_browse_id", browse_id
        ).order("created_at", desc=True).execute()

        all_tracks = tracks_result.data or []

        # ì•¨ë²”ë³„ë¡œ íŠ¸ë™ ê·¸ë£¹í™”
        album_tracks_map = {}
        for track in all_tracks:
            album_id = track.get("album_browse_id")
            if album_id:
                if album_id not in album_tracks_map:
                    album_tracks_map[album_id] = []
                album_tracks_map[album_id].append({
                    "videoId": track.get("video_id"),
                    "title": track.get("title"),
                    "duration": track.get("duration"),
                    "trackNumber": track.get("track_number"),
                    "thumbnails": [{"url": track.get("thumbnail_url")}] if track.get("thumbnail_url") else []
                })

        # ì•¨ë²”ì— íŠ¸ë™ ì¶”ê°€
        albums_with_tracks = []
        for album in albums:
            album_entry = {
                "browseId": album.get("browse_id"),
                "title": album.get("title"),
                "type": album.get("type"),
                "year": album.get("year"),
                "thumbnails": [{"url": album.get("thumbnail_url")}] if album.get("thumbnail_url") else [],
                "tracks": album_tracks_map.get(album.get("browse_id"), [])
            }
            albums_with_tracks.append(album_entry)

        return {
            "browseId": artist.get("browse_id"),
            "artist": artist.get("name"),
            "name": artist.get("name"),
            "thumbnails": [{"url": artist.get("thumbnail_url")}] if artist.get("thumbnail_url") else [],
            "subscribers": artist.get("subscribers"),
            "description": artist.get("description"),
            "topSongs": artist.get("top_songs_json") or [],
            "related": artist.get("related_artists_json") or [],
            "albums": albums_with_tracks,
            "allTracks": [{
                "videoId": t.get("video_id"),
                "title": t.get("title"),
                "duration": t.get("duration"),
                "albumTitle": next((a.get("title") for a in albums if a.get("browse_id") == t.get("album_browse_id")), ""),
                "thumbnails": [{"url": t.get("thumbnail_url")}] if t.get("thumbnail_url") else []
            } for t in all_tracks],
            "last_synced_at": artist.get("last_synced_at"),
            # ì¸ê¸°ê³¡ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë§Œ ë°˜í™˜ (YouTube IFrame APIìš©)
            "songsPlaylistId": artist.get("songs_playlist_id")
        }
    except Exception as e:
        logger.warning(f"DB get full artist data error: {e}")
        return None

def get_best_thumbnail(thumbnails: list) -> str:
    """ì¸ë„¤ì¼ ëª©ë¡ì—ì„œ ê°€ì¥ ì¢‹ì€ URL ì„ íƒ"""
    if not thumbnails:
        return ""
    # ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ
    best = thumbnails[-1]
    return best.get("url", "") if isinstance(best, dict) else ""


def background_update_artist(artist_browse_id: str, country: str):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì•„í‹°ìŠ¤íŠ¸ ë°ì´í„° ì—…ë°ì´íŠ¸ (7ì¼ ê²½ê³¼ ì‹œ í˜¸ì¶œ)
    - ìƒˆ ì•¨ë²”/ì‹±ê¸€ í™•ì¸
    - ìƒˆ íŠ¸ë™ë§Œ DBì— ì¶”ê°€ (ê¸°ì¡´ ë°ì´í„° ìœ ì§€)
    """
    try:
        from ytmusicapi import YTMusic

        logger.info(f"Background update started: {artist_browse_id}")

        # ê¸°ì¡´ ì•¨ë²”/íŠ¸ë™ ID ì¡°íšŒ
        existing_album_ids = db_get_existing_album_ids(artist_browse_id)
        existing_video_ids = db_get_existing_video_ids(artist_browse_id)

        # ytmusicapië¡œ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        lang = COUNTRY_LANGUAGE_MAP.get(country.upper(), 'en')
        ytmusic = YTMusic(language=lang, location=country.upper())

        artist_info = ytmusic.get_artist(artist_browse_id)
        if not artist_info:
            logger.warning(f"Background update: Artist not found {artist_browse_id}")
            return

        new_albums_count = 0
        new_tracks_count = 0

        # ì•¨ë²” í™•ì¸
        albums_section = artist_info.get("albums")
        if albums_section and isinstance(albums_section, dict):
            params = albums_section.get("params")
            browse_id = albums_section.get("browseId")
            album_list = []

            if params and browse_id:
                try:
                    album_list = ytmusic.get_artist_albums(browse_id, params) or []
                except Exception:
                    album_list = albums_section.get("results") or []
            else:
                album_list = albums_section.get("results") or []

            for album in album_list:
                album_browse_id = album.get("browseId")
                if not album_browse_id or album_browse_id in existing_album_ids:
                    continue

                # ìƒˆ ì•¨ë²” ë°œê²¬!
                try:
                    album_detail = ytmusic.get_album(album_browse_id)
                    if not album_detail:
                        continue

                    album_data = {
                        "browseId": album_browse_id,
                        "title": album_detail.get("title") or "",
                        "type": album_detail.get("type") or "Album",
                        "year": album_detail.get("year") or "",
                        "thumbnails": album_detail.get("thumbnails") or []
                    }

                    db_save_album(album_data, artist_browse_id)
                    new_albums_count += 1

                    # íŠ¸ë™ ì €ì¥
                    for idx, track in enumerate(album_detail.get("tracks") or []):
                        video_id = track.get("videoId")
                        if not video_id or video_id in existing_video_ids:
                            continue

                        track_data = {
                            "videoId": video_id,
                            "title": track.get("title") or "",
                            "duration": track.get("duration") or "",
                            "thumbnails": track.get("thumbnails") or [],
                            "isExplicit": track.get("isExplicit", False)
                        }

                        db_save_track(track_data, album_browse_id, artist_browse_id, idx + 1)
                        new_tracks_count += 1

                except Exception as e:
                    logger.warning(f"Background album fetch error: {e}")

        # ì‹±ê¸€ í™•ì¸
        singles_section = artist_info.get("singles")
        if singles_section and isinstance(singles_section, dict):
            params = singles_section.get("params")
            browse_id = singles_section.get("browseId")
            singles_list = []

            if params and browse_id:
                try:
                    singles_list = ytmusic.get_artist_albums(browse_id, params) or []
                except Exception:
                    singles_list = singles_section.get("results") or []
            else:
                singles_list = singles_section.get("results") or []

            for single in singles_list:
                single_browse_id = single.get("browseId")
                if not single_browse_id or single_browse_id in existing_album_ids:
                    continue

                try:
                    single_detail = ytmusic.get_album(single_browse_id)
                    if not single_detail:
                        continue

                    single_data = {
                        "browseId": single_browse_id,
                        "title": single_detail.get("title") or "",
                        "type": "Single",
                        "year": single_detail.get("year") or "",
                        "thumbnails": single_detail.get("thumbnails") or []
                    }

                    db_save_album(single_data, artist_browse_id)
                    new_albums_count += 1

                    for idx, track in enumerate(single_detail.get("tracks") or []):
                        video_id = track.get("videoId")
                        if not video_id or video_id in existing_video_ids:
                            continue

                        track_data = {
                            "videoId": video_id,
                            "title": track.get("title") or "",
                            "duration": track.get("duration") or "",
                            "thumbnails": track.get("thumbnails") or [],
                            "isExplicit": track.get("isExplicit", False)
                        }

                        db_save_track(track_data, single_browse_id, artist_browse_id, idx + 1)
                        new_tracks_count += 1

                except Exception as e:
                    logger.warning(f"Background single fetch error: {e}")

        # ì¸ê¸°ê³¡ ì—…ë°ì´íŠ¸
        top_songs = []
        songs_section = artist_info.get("songs")
        if songs_section and isinstance(songs_section, dict):
            for song in songs_section.get("results", []):
                if isinstance(song, dict) and song.get("videoId"):
                    top_songs.append({
                        "videoId": song.get("videoId"),
                        "title": song.get("title") or "",
                        "duration": song.get("duration") or "",
                        "thumbnails": song.get("thumbnails") or []
                    })

        # ìœ ì‚¬ ì•„í‹°ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        related_artists = []
        related_section = artist_info.get("related")
        if related_section and isinstance(related_section, dict):
            for rel in related_section.get("results", [])[:15]:
                if isinstance(rel, dict):
                    related_artists.append({
                        "browseId": rel.get("browseId") or "",
                        "name": rel.get("title") or rel.get("name") or "",
                        "subscribers": rel.get("subscribers") or "",
                        "thumbnails": rel.get("thumbnails") or []
                    })

        # last_synced_at ì—…ë°ì´íŠ¸
        if supabase_client:
            try:
                supabase_client.table("music_artists").update({
                    "top_songs_json": top_songs,
                    "related_artists_json": related_artists,
                    "last_synced_at": datetime.now(timezone.utc).isoformat()
                }).eq("browse_id", artist_browse_id).execute()
            except Exception as e:
                logger.warning(f"Background update artist error: {e}")

        logger.info(f"Background update completed: {artist_browse_id} - {new_albums_count} new albums, {new_tracks_count} new tracks")

    except Exception as e:
        logger.error(f"Background update error: {e}")


def db_get_existing_video_ids(artist_browse_id: str) -> set:
    """ì•„í‹°ìŠ¤íŠ¸ì˜ ê¸°ì¡´ video_id ëª©ë¡ ì¡°íšŒ (ì¤‘ë³µ ë°©ì§€ìš©)"""
    if not supabase_client or not artist_browse_id:
        return set()

    try:
        result = supabase_client.table("music_tracks").select("video_id").eq(
            "artist_browse_id", artist_browse_id
        ).execute()

        return {r.get("video_id") for r in (result.data or []) if r.get("video_id")}
    except Exception as e:
        logger.warning(f"DB get existing video_ids error: {e}")
        return set()

def db_get_existing_album_ids(artist_browse_id: str) -> set:
    """ì•„í‹°ìŠ¤íŠ¸ì˜ ê¸°ì¡´ album browse_id ëª©ë¡ ì¡°íšŒ (ì¤‘ë³µ ë°©ì§€ìš©)"""
    if not supabase_client or not artist_browse_id:
        return set()

    try:
        result = supabase_client.table("music_albums").select("browse_id").eq(
            "artist_browse_id", artist_browse_id
        ).execute()

        return {r.get("browse_id") for r in (result.data or []) if r.get("browse_id")}
    except Exception as e:
        logger.warning(f"DB get existing album_ids error: {e}")
        return set()

def db_artist_needs_update(browse_id: str, hours: int = 6) -> bool:
    """ì•„í‹°ìŠ¤íŠ¸ê°€ ì—…ë°ì´íŠ¸ í•„ìš”í•œì§€ í™•ì¸ (ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ í›„ Nì‹œê°„ ê²½ê³¼)"""
    if not supabase_client or not browse_id:
        return True

    try:
        result = supabase_client.table("music_artists").select("last_updated").eq(
            "browse_id", browse_id
        ).single().execute()

        if not result.data:
            return True  # ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ í•„ìš”

        last_updated = result.data.get("last_updated")
        if not last_updated:
            return True

        last_time = datetime.fromisoformat(last_updated.replace("Z", "+00:00"))
        return datetime.now(timezone.utc) - last_time > timedelta(hours=hours)
    except Exception as e:
        logger.warning(f"DB artist needs update check error: {e}")
        return True

def db_save_related_artists(main_artist_browse_id: str, related_artists: list):
    """ìœ ì‚¬ ì•„í‹°ìŠ¤íŠ¸ ê´€ê³„ ì €ì¥"""
    if not supabase_client or not related_artists:
        return

    try:
        for related in related_artists:
            related_browse_id = related.get("browseId")
            if not related_browse_id:
                continue

            # ë¨¼ì € ê´€ë ¨ ì•„í‹°ìŠ¤íŠ¸ë„ music_artists í…Œì´ë¸”ì— ì €ì¥
            db_save_artist(related)

            # ê´€ê³„ ì €ì¥
            data = {
                "main_artist_browse_id": main_artist_browse_id,
                "related_artist_browse_id": related_browse_id,
                "relation_type": "similar"
            }

            supabase_client.table("artist_relations").upsert(
                data, on_conflict="main_artist_browse_id,related_artist_browse_id"
            ).execute()

        logger.info(f"Saved {len(related_artists)} related artists for {main_artist_browse_id}")
    except Exception as e:
        logger.warning(f"DB save related artists error: {e}")

def db_save_search_cache(keyword: str, country: str, artist_ids: list):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥"""
    if not supabase_client or not artist_ids:
        return

    try:
        data = {
            "keyword": keyword,
            "keyword_normalized": keyword.lower(),
            "country": country,
            "artist_ids": artist_ids,
            "result_count": len(artist_ids),
            "last_searched": datetime.now(timezone.utc).isoformat()
        }

        supabase_client.table("music_search_cache").upsert(
            data, on_conflict="keyword_normalized,country"
        ).execute()

    except Exception as e:
        logger.warning(f"DB save search cache error: {e}")

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    logger.info("ğŸš€ MusicGram API starting...")
    yield
    # ì¢…ë£Œ ì‹œ
    logger.info("ğŸ‘‹ MusicGram API shutting down...")

# FastAPI ì•±
app = FastAPI(
    title="MusicGram API",
    description="YouTube Music ê¸°ë°˜ ìŒì•… í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì†Œì…œ í”Œë«í¼ API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ í—ˆìš©)
allowed_origins = os.getenv("ALLOWED_ORIGINS", "*").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# í—¬ìŠ¤ ì²´í¬
# =============================================================================

@app.get("/")
async def root():
    return {
        "service": "MusicGram API",
        "status": "running",
        "version": "1.0.0"
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "database": "connected" if supabase_client else "not configured"
    }

# =============================================================================
# ìŒì•… ê²€ìƒ‰ API
# =============================================================================

@app.get("/api/search")
async def search_music(
    request: Request,
    q: str,
    filter: str = "songs",
    limit: int = 20,
    country: str = None
):
    """ìŒì•… ê²€ìƒ‰"""
    # êµ­ê°€ ê°ì§€ (í—¤ë” ë˜ëŠ” íŒŒë¼ë¯¸í„°)
    if not country:
        country = request.headers.get("CF-IPCountry", "US")
    
    # ìºì‹œ í‚¤
    cache_key = f"search:{country}:{filter}:{q}"
    
    # ìºì‹œ í™•ì¸
    cached = cache_get(cache_key)
    if cached:
        logger.info(f"Cache hit: {cache_key}")
        return {"source": "cache", "results": cached}
    
    # API í˜¸ì¶œ
    try:
        ytmusic = get_ytmusic(country)
        results = ytmusic.search(q, filter=filter, limit=limit)
        
        # ìºì‹œ ì €ì¥ (30ë¶„)
        cache_set(cache_key, results, ttl=1800)
        
        return {"source": "api", "results": results}
    except Exception as e:
        logger.error(f"Search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì°¨íŠ¸ API
# =============================================================================

@app.get("/api/charts")
async def get_charts(request: Request, country: str = None):
    """êµ­ê°€ë³„ ì¸ê¸° ì°¨íŠ¸"""
    if not country:
        country = request.headers.get("CF-IPCountry", "US")
    
    cache_key = f"charts:{country}"
    
    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "charts": cached}
    
    try:
        ytmusic = get_ytmusic(country)
        charts = ytmusic.get_charts(country=country)
        
        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, charts, ttl=3600)
        
        return {"country": country, "source": "api", "charts": charts}
    except Exception as e:
        logger.error(f"Charts error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì‹ ê·œ ì•¨ë²” API
# =============================================================================

@app.get("/api/new-albums")
async def get_new_albums(request: Request, country: str = None):
    """êµ­ê°€ë³„ ì‹ ê·œ ì•¨ë²”"""
    if not country:
        country = request.headers.get("CF-IPCountry", "US")
    
    cache_key = f"new_albums:{country}"
    
    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "albums": cached}
    
    try:
        ytmusic = get_ytmusic(country)
        albums = ytmusic.get_new_albums()
        
        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, albums, ttl=3600)
        
        return {"country": country, "source": "api", "albums": albums}
    except Exception as e:
        logger.error(f"New albums error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# Mood & Genre API (ì¶”ì²œ ìŒì•…)
# =============================================================================

@app.get("/api/moods")
async def get_moods(request: Request, country: str = None):
    """ë¬´ë“œ & ì¥ë¥´ ì¹´í…Œê³ ë¦¬ ëª©ë¡"""
    if not country:
        country = request.headers.get("CF-IPCountry", "US")

    cache_key = f"moods:{country}"

    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "moods": cached}

    try:
        ytmusic = get_ytmusic(country)
        moods = ytmusic.get_mood_categories()

        # 6ì‹œê°„ ìºì‹œ
        cache_set(cache_key, moods, ttl=21600)

        return {"country": country, "source": "api", "moods": moods}
    except Exception as e:
        logger.error(f"Moods error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/mood-playlists")
async def get_mood_playlists(params: str, country: str = None, request: Request = None):
    """íŠ¹ì • ë¬´ë“œ/ì¥ë¥´ì˜ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ëª©ë¡"""
    if not country:
        country = request.headers.get("CF-IPCountry", "US") if request else "US"

    cache_key = f"mood_playlists:{params}:{country}"

    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "playlists": cached}

    try:
        ytmusic = get_ytmusic(country)
        playlists = ytmusic.get_mood_playlists(params)

        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, playlists, ttl=3600)

        return {"country": country, "source": "api", "playlists": playlists}
    except Exception as e:
        logger.error(f"Mood playlists error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/home")
async def get_home_feed(request: Request, country: str = None, limit: int = 6):
    """
    í™ˆ í™”ë©´ ì¶”ì²œ ì½˜í…ì¸  - ytmusic.get_home() ì‚¬ìš©
    YouTube Music í™ˆ í™”ë©´ê³¼ ë™ì¼í•œ ì¶”ì²œ ì„¹ì…˜ ë°˜í™˜
    (Quick picks, ë¯¹ìŠ¤, ì¶”ì²œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸, ì‹ ê·œ ì•¨ë²” ë“±)
    """
    if not country:
        country = request.headers.get("CF-IPCountry", "US")

    cache_key = f"home_feed:{country}:{limit}"

    cached = cache_get(cache_key)
    if cached:
        return {"country": country, "source": "cache", "sections": cached}

    # ì¬ì‹œë„ ë¡œì§ (YTMusic API ê°„í—ì  ë¹ˆ ì‘ë‹µ ëŒ€ì‘)
    max_retries = 3
    last_error = None

    for attempt in range(max_retries):
        try:
            ytmusic = get_ytmusic(country)

            # get_home()ì€ í™ˆ í™”ë©´ì˜ ëª¨ë“  ì„¹ì…˜ì„ ë°˜í™˜
            home_sections = ytmusic.get_home(limit=limit)

            # ìœ íš¨í•œ ì‘ë‹µì¸ì§€ í™•ì¸
            if home_sections and isinstance(home_sections, list) and len(home_sections) > 0:
                # 30ë¶„ ìºì‹œ
                cache_set(cache_key, home_sections, ttl=1800)
                return {"country": country, "source": "api", "sections": home_sections}
            else:
                logger.warning(f"Home feed empty response (attempt {attempt + 1}/{max_retries})")
                last_error = "Empty response from YTMusic API"

        except Exception as e:
            logger.warning(f"Home feed attempt {attempt + 1}/{max_retries} failed: {e}")
            last_error = str(e)

        # ì¬ì‹œë„ ì „ ëŒ€ê¸° (exponential backoff)
        if attempt < max_retries - 1:
            await asyncio.sleep(0.5 * (attempt + 1))

    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ë¹ˆ ì‘ë‹µ ë°˜í™˜ (500 ì—ëŸ¬ ëŒ€ì‹ )
    logger.error(f"Home feed failed after {max_retries} attempts: {last_error}")
    return {"country": country, "source": "fallback", "sections": [], "error": "Temporary service unavailable"}


# =============================================================================
# Summary Search API - ì •ê·œí™” DB ì‚¬ìš© (ì „ì²´ ë””ìŠ¤ì½”ê·¸ë˜í”¼)
# =============================================================================

# =============================================================================
# Summary Search API - ì •ê·œí™” DB ì‚¬ìš© (ì „ì²´ ë””ìŠ¤ì½”ê·¸ë˜í”¼)
# =============================================================================

def save_full_artist_data_background(artist_id: str, artist_info: dict, country: str):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì•„í‹°ìŠ¤íŠ¸ì˜ ì „ì²´ ì•¨ë²”/ì‹±ê¸€/íŠ¸ë™ ì •ë³´ë¥¼ ê°€ì ¸ì™€ DBì— ì €ì¥"""
    try:
        ytmusic = get_ytmusic(country)

        # 1. ì•„í‹°ìŠ¤íŠ¸ ê¸°ë³¸ ì •ë³´ ì €ì¥
        artist_name = artist_info.get("name") or ""
        search_thumbnails = artist_info.get("thumbnails") or []

        # ì¸ê¸°ê³¡ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ì¶”ì¶œ (í•µì‹¬!)
        songs_playlist_id = None
        songs_browse_id = None
        songs_section = artist_info.get("songs")
        if songs_section and isinstance(songs_section, dict):
            songs_browse_id = songs_section.get("browseId")
            if songs_browse_id and songs_browse_id.startswith("VL"):
                songs_playlist_id = songs_browse_id[2:]
            elif songs_browse_id:
                songs_playlist_id = songs_browse_id

        # ì¸ê¸°ê³¡ ì¶”ì¶œ & ì €ì¥ (ê²€ìƒ‰ìš© ë©”íƒ€ë°ì´í„°)
        top_songs = []
        if songs_section and isinstance(songs_section, dict):
            for song in songs_section.get("results", []):
                if isinstance(song, dict) and song.get("videoId"):
                    top_songs.append({
                        "videoId": song.get("videoId"),
                        "title": song.get("title") or "",
                        "duration": song.get("duration") or "",
                        "thumbnails": song.get("thumbnails") or []
                    })
        
        # ìœ ì‚¬ ì•„í‹°ìŠ¤íŠ¸ ì¶”ì¶œ & ì €ì¥
        related_artists = []
        related_section = artist_info.get("related")
        if related_section and isinstance(related_section, dict):
            for rel in related_section.get("results", [])[:15]:
                if isinstance(rel, dict):
                    related_artists.append({
                        "browseId": rel.get("browseId") or "",
                        "name": rel.get("title") or rel.get("name") or "",
                        "subscribers": rel.get("subscribers") or "",
                        "thumbnails": rel.get("thumbnails") or []
                    })
        
        artist_data = {
            "browseId": artist_id,
            "artist": artist_name,
            "name": artist_name,
            "thumbnails": search_thumbnails,
            "subscribers": artist_info.get("subscribers") or "",
            "description": artist_info.get("description") or "",
            "topSongs": top_songs,
            "related": related_artists,
            "songsPlaylistId": songs_playlist_id  # YouTube IFrame APIìš© í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë§Œ
        }

        db_save_artist_full(artist_data)
        
        # 2. ì•¨ë²”/ì‹±ê¸€ ì „ì²´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° & ì €ì¥
        try:
            # ì•¨ë²”
            albums_section = artist_info.get("albums")
            if albums_section and isinstance(albums_section, dict):
                params = albums_section.get("params")
                browse_id = albums_section.get("browseId")
                
                album_list = []
                if params and browse_id:
                    album_list = ytmusic.get_artist_albums(browse_id, params) or []
                else:
                    album_list = albums_section.get("results") or []
                    
                for album in album_list:
                     if isinstance(album, dict) and album.get("browseId"):
                        album_data = {
                            "browseId": album.get("browseId"),
                            "title": album.get("title") or "",
                            "type": album.get("type") or "Album",
                            "year": album.get("year") or "",
                            "thumbnails": album.get("thumbnails") or [],
                            "tracks": []
                        }
                        db_save_album(album_data, artist_id)
            
            # ì‹±ê¸€
            singles_section = artist_info.get("singles")
            if singles_section and isinstance(singles_section, dict):
                params = singles_section.get("params")
                browse_id = singles_section.get("browseId")
                
                singles_list = []
                if params and browse_id:
                    singles_list = ytmusic.get_artist_albums(browse_id, params) or []
                else:
                    singles_list = singles_section.get("results") or []
                    
                for single in singles_list:
                     if isinstance(single, dict) and single.get("browseId"):
                        single_data = {
                            "browseId": single.get("browseId"),
                            "title": single.get("title") or "",
                            "type": "Single",
                            "year": single.get("year") or "",
                            "thumbnails": single.get("thumbnails") or [],
                            "tracks": []
                        }
                        db_save_album(single_data, artist_id)
                        
        except Exception as e:
            logger.warning(f"Background album save error: {e}")
            
        logger.info(f"Background save completed for artist: {artist_name}")

    except Exception as e:
        logger.error(f"Background save error: {e}")

def parse_artist_data_lightweight(artist_id: str, artist_info: dict) -> dict:
    """
    ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë¹ ë¥´ê²Œ íŒŒì‹±í•˜ì—¬ ì‘ë‹µìš©ìœ¼ë¡œ ë°˜í™˜ (DB ì €ì¥ X, ì¶”ê°€ Fetch X)
    """
    artist_name = artist_info.get("name") or ""
    search_thumbnails = artist_info.get("thumbnails") or []

    # ì¸ê¸°ê³¡
    top_songs = []
    songs_section = artist_info.get("songs")
    if songs_section and isinstance(songs_section, dict):
        for song in songs_section.get("results", []):
            if isinstance(song, dict) and song.get("videoId"):
                top_songs.append({
                    "videoId": song.get("videoId"),
                    "title": song.get("title") or "",
                    "duration": song.get("duration") or "",
                    "thumbnails": song.get("thumbnails") or []
                })

    # ìœ ì‚¬ ì•„í‹°ìŠ¤íŠ¸
    related_artists = []
    related_section = artist_info.get("related")
    if related_section and isinstance(related_section, dict):
        for rel in related_section.get("results", [])[:15]:
            if isinstance(rel, dict):
                related_artists.append({
                    "browseId": rel.get("browseId") or "",
                    "name": rel.get("title") or rel.get("name") or "",
                    "subscribers": rel.get("subscribers") or "",
                    "thumbnails": rel.get("thumbnails") or []
                })

    # ì•¨ë²” ëª©ë¡ (ë©”ì¸ í˜ì´ì§€ì— ìˆëŠ” ê²ƒë§Œ ìš°ì„  ë°˜í™˜)
    all_albums = []
    
    albums_section = artist_info.get("albums")
    if albums_section and isinstance(albums_section, dict):
        for album in albums_section.get("results") or []:
            if isinstance(album, dict) and album.get("browseId"):
                all_albums.append({
                    "browseId": album.get("browseId"),
                    "title": album.get("title") or "",
                    "type": album.get("type") or "Album",
                    "year": album.get("year") or "",
                    "thumbnails": album.get("thumbnails") or [],
                    "tracks": []
                })

    singles_section = artist_info.get("singles")
    if singles_section and isinstance(singles_section, dict):
        for single in singles_section.get("results") or []:
             if isinstance(single, dict) and single.get("browseId"):
                all_albums.append({
                    "browseId": single.get("browseId"),
                    "title": single.get("title") or "",
                    "type": "Single",
                    "year": single.get("year") or "",
                    "thumbnails": single.get("thumbnails") or [],
                    "tracks": []
                })

    return {
        "browseId": artist_id,
        "artist": artist_name,
        "name": artist_name,
        "thumbnails": search_thumbnails,
        "subscribers": artist_info.get("subscribers") or "",
        "description": artist_info.get("description") or "",
        "topSongs": top_songs,
        "related": related_artists,
        "albums": all_albums,
        "allTracks": top_songs # ì´ˆê¸° ì‘ë‹µì—ëŠ” top songsë§Œ í¬í•¨
    }


@app.get("/api/search/summary/deprecated")
async def search_summary_deprecated(
    request: Request,
    q: str,
    background_tasks: BackgroundTasks,
    country: str = None,
    force_refresh: bool = False
):
    """
    ì•„í‹°ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ì „ì²´ ë””ìŠ¤ì½”ê·¸ë˜í”¼ ë°˜í™˜

    Data Flow:
    1. DBì—ì„œ ê²€ìƒ‰ì–´ ë§¤í•‘ í™•ì¸ (search_keywords)
    2. ë§¤í•‘ ìˆìŒ â†’ DBì—ì„œ ì „ì²´ ë°ì´í„° ë°˜í™˜
       - 7ì¼ ê²½ê³¼ ì‹œ â†’ ë°˜í™˜ í›„ ë°±ê·¸ë¼ìš´ë“œ ì—…ë°ì´íŠ¸
    3. ë§¤í•‘ ì—†ìŒ â†’ ytmusicapi í˜¸ì¶œ â†’ ì „ì²´ ë””ìŠ¤ì½”ê·¸ë˜í”¼ â†’ DB ì €ì¥
    """
    if not country:
        country = request.headers.get("CF-IPCountry", "US")

    cache_key = f"summary:{country}:{q}"

    # ==========================================================================
    # 1ë‹¨ê³„: DBì—ì„œ ê¸°ì¡´ ë°ì´í„° í™•ì¸
    # ==========================================================================
    if not force_refresh:
        # Redis ìºì‹œ ë¨¼ì € í™•ì¸ (ë¹ ë¥¸ ì‘ë‹µ)
        cached = cache_get(cache_key)
        if cached:
            logger.info(f"Redis cache hit: {cache_key}")
            cached["source"] = "redis"
            return cached

        # DBì—ì„œ ê²€ìƒ‰ì–´ ë§¤í•‘ í™•ì¸
        artist_browse_ids = db_get_artists_by_keyword(q, country)
        if artist_browse_ids:
            logger.info(f"DB hit for keyword: {q} ({len(artist_browse_ids)} artists)")

            artists_data = []
            all_songs = []
            all_albums = []
            needs_background_update = False

            for browse_id in artist_browse_ids:
                artist_full = db_get_full_artist_data(browse_id)
                if artist_full:
                    artists_data.append(artist_full)

                    # ì¸ê¸°ê³¡ì„ songsì— ì¶”ê°€
                    for song in artist_full.get("topSongs", []):
                        song["artist_bid"] = browse_id
                        song["resultType"] = "song"
                        all_songs.append(song)

                    # ì•¨ë²” ì¶”ê°€
                    for album in artist_full.get("albums", []):
                        album["artist_bid"] = browse_id
                        all_albums.append(album)

                    # 7ì¼ ê²½ê³¼ ì²´í¬
                    if db_check_artist_needs_sync(browse_id, days=7):
                        needs_background_update = True
                        # ë°±ê·¸ë¼ìš´ë“œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
                        background_tasks.add_task(background_update_artist, browse_id, country)

            if artists_data:
                result = {
                    "keyword": q,
                    "country": country,
                    "artists": artists_data,
                    "songs": all_songs,
                    "albums": [],
                    "albums2": all_albums,
                    "allTracks": [t for a in artists_data for t in a.get("allTracks", [])],
                    "source": "database",
                    "updating": needs_background_update  # ì—…ë°ì´íŠ¸ ì¤‘ì„ì„ ì•Œë¦¼
                }

                # Redisì— ìºì‹œ
                cache_set(cache_key, result, ttl=1800)

                if needs_background_update:
                    logger.info(f"Background update triggered for: {q}")

                return result

    # ==========================================================================
    # 2ë‹¨ê³„: ytmusicapiì—ì„œ ìƒˆë¡œ ê°€ì ¸ì˜¤ê¸° (ë³‘ë ¬ ì²˜ë¦¬ + ë°±ê·¸ë¼ìš´ë“œ ì €ì¥)
    # ==========================================================================
    logger.info(f"Fetching from ytmusicapi: {q}")

    try:
        ytmusic = get_ytmusic(country)

        # 1. ì•„í‹°ìŠ¤íŠ¸ì™€ ë…¸ë˜ ë™ì‹œ ê²€ìƒ‰ (ë³‘ë ¬ ì‹¤í–‰)
        # run_in_threadë¥¼ ì‚¬ìš©í•˜ì—¬ blocking I/Oë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        future_artists = run_in_thread(ytmusic.search, q, filter="artists", limit=5)
        future_songs = run_in_thread(ytmusic.search, q, filter="songs", limit=20) # 30 -> 20 limit ì¶•ì†Œ
        
        # ë³‘ë ¬ ëŒ€ê¸°
        artists_results, direct_song_results = await asyncio.gather(future_artists, future_songs)
        
        # ê²°ê³¼ ì²˜ë¦¬
        artists_search = artists_results or []
        if not artists_search:
            # Fallback: ì¼ë°˜ ê²€ìƒ‰ì—ì„œ ì•„í‹°ìŠ¤íŠ¸ í•„í„°ë§
            general_results = await run_in_thread(ytmusic.search, q, limit=40)
            artists_search = [r for r in general_results if r.get("resultType") == "artist"][:5]

        # ë…¸ë˜ ê²°ê³¼ ì •ì œ
        songs_search = []
        direct_song_results = direct_song_results or []
        for song in direct_song_results:
            if isinstance(song, dict) and song.get("videoId"):
                song_copy = dict(song)
                song_copy["resultType"] = "song"
                song_copy["from_direct_search"] = True
                songs_search.append(song_copy)

        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì•„í‹°ìŠ¤íŠ¸ 1ëª…ë§Œ ì²˜ë¦¬
        artists_data = []
        albums_data = []
        all_tracks = []
        best_artist = None
        search_lower = q.lower().strip()

        # ìµœì ì˜ ì•„í‹°ìŠ¤íŠ¸ ë§¤ì¹­
        for artist in artists_search[:5]:
            if not isinstance(artist, dict):
                continue
            artist_name = (artist.get("artist") or artist.get("name") or "").lower()
            if search_lower in artist_name or artist_name in search_lower:
                best_artist = artist
                break
        
        if not best_artist and artists_search:
            best_artist = artists_search[0]

        if best_artist and isinstance(best_artist, dict):
            artist_id = best_artist.get("browseId")
            if artist_id:
                try:
                    # ì•„í‹°ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    artist_info = await run_in_thread(ytmusic.get_artist, artist_id)
                    
                    if artist_info and isinstance(artist_info, dict):
                        # 1. ì‘ë‹µìš© ê°€ë²¼ìš´ ë°ì´í„° íŒŒì‹± (Blocking ì—†ìŒ)
                        artist_full = parse_artist_data_lightweight(artist_id, artist_info)
                        
                        if artist_full:
                            artists_data.append(artist_full)

                            # 2. ê²°ê³¼ ì¡°í•©
                            # ì¸ê¸°ê³¡ì„ songs ë¦¬ìŠ¤íŠ¸ ìƒë‹¨ì— ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ë†’ì„)
                            top_songs = []
                            for song in artist_full.get("topSongs", []):
                                song["artist_bid"] = artist_id
                                song["resultType"] = "song"
                                top_songs.append(song)
                            
                            # ë…¸ë˜ ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°: [ì•„í‹°ìŠ¤íŠ¸ ì¸ê¸°ê³¡] + [ê²€ìƒ‰ëœ ë…¸ë˜ ì¤‘ ì•„í‹°ìŠ¤íŠ¸ ì¼ì¹˜í•˜ëŠ” ê³¡] + [ë‚˜ë¨¸ì§€]
                            # ì™¸êµ­ íŒì†¡ í•„í„°ë§: ì•„í‹°ìŠ¤íŠ¸ê°€ í™•ì‹¤í•˜ë‹¤ë©´, í•´ë‹¹ ì•„í‹°ìŠ¤íŠ¸ì˜ ë…¸ë˜ ìœ„ì£¼ë¡œ êµ¬ì„±
                            
                            filtered_search_songs = []
                            other_songs = []
                            target_artist_name = artist_full.get("name", "").lower()

                            for s in songs_search:
                                # ë…¸ë˜ì˜ ì•„í‹°ìŠ¤íŠ¸ ëª©ë¡ í™•ì¸
                                s_artists = s.get("artists") or []
                                is_match = False
                                for a in s_artists:
                                    if a.get("name", "").lower() == target_artist_name:
                                        is_match = True
                                        break
                                if is_match:
                                    filtered_search_songs.append(s)
                                else:
                                    other_songs.append(s)
                            
                            # ìµœì¢… ë…¸ë˜ ëª©ë¡ ì¬êµ¬ì„±: ì¸ê¸°ê³¡ -> ê²€ìƒ‰ëœ ì•„í‹°ìŠ¤íŠ¸ ê³¡ -> (í•„ìš”ì‹œ) ë‚˜ë¨¸ì§€ ê³¡
                            songs_search = top_songs + filtered_search_songs
                            
                            # ë‚˜ë¨¸ì§€ê°€ ë„ˆë¬´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ê³¡ë„ ì¡°ê¸ˆ ì¶”ê°€ (ë‹¨, í•œêµ­ ê°€ìˆ˜ì˜ ê²½ìš° ì™¸êµ­ê³¡ ì œì™¸ ë¡œì§ì€ ì´ë¦„ ë§¤ì¹­ìœ¼ë¡œ ì–´ëŠ ì •ë„ í•´ê²°)
                            if len(songs_search) < 5:
                                songs_search += other_songs[:5]

                            # ì•¨ë²” ë°ì´í„° ì¶”ê°€
                            for album in artist_full.get("albums", []):
                                album["artist_bid"] = artist_id
                                albums_data.append(album)

                            # 3. ë¬´ê±°ìš´ ì‘ì—…(DB ì €ì¥, ì „ì²´ ì•¨ë²” Fetch)ì€ ë°±ê·¸ë¼ìš´ë“œë¡œ ìœ„ì„
                            background_tasks.add_task(save_full_artist_data_background, artist_id, artist_info, country)
                            background_tasks.add_task(db_save_search_keyword, q, country, artist_id)

                except Exception as artist_err:
                    logger.warning(f"Artist fetch error for {artist_id}: {artist_err}")

        result = {
            "keyword": q,
            "country": country,
            "artists": artists_data,
            "songs": songs_search,
            "albums": [],
            "albums2": albums_data,
            "allTracks": all_tracks,
            "source": "ytmusicapi"
        }

        # Redis ìºì‹œ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ)
        # cache_setë„ ê°€ë²¼ìš´ ì—°ì‚°ì´ë¯€ë¡œ ê·¸ëƒ¥ ì‹¤í–‰í•˜ê±°ë‚˜ ë¹„ë™ê¸° ì²˜ë¦¬ ê°€ëŠ¥í•˜ë‚˜ ì—¬ê¸°ì„  ìœ ì§€
        cache_set(cache_key, result, ttl=1800)

        return result

    except Exception as e:
        logger.error(f"Summary search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# ì•„í‹°ìŠ¤íŠ¸ ì •ë³´ API
# =============================================================================

@app.get("/api/artist/{artist_id}/songs-playlist")
async def get_artist_songs_playlist(artist_id: str, country: str = "US"):
    """
    ì•„í‹°ìŠ¤íŠ¸ì˜ "ì¸ê¸°ê³¡ ëª¨ë‘ í‘œì‹œ" í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ë°˜í™˜

    YouTube Music ì•„í‹°ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ "ì¸ê¸°ê³¡" ì„¹ì…˜ì˜ "ëª¨ë‘ í‘œì‹œ" ë²„íŠ¼ ë§í¬ì— ìˆëŠ”
    í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.

    ì´ IDë¥¼ YouTube IFrame APIì˜ loadPlaylist()ì— ì „ë‹¬í•˜ë©´
    í•´ë‹¹ ì•„í‹°ìŠ¤íŠ¸ì˜ ì „ì²´ ì¸ê¸°ê³¡ì„ ìë™ìœ¼ë¡œ ì¬ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    Returns:
        - playlistId: ìˆœìˆ˜ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID (VL ì ‘ë‘ì‚¬ ì œê±°ë¨)
        - browseId: ì›ë³¸ browseId (VL í¬í•¨)
        - artistName: ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„
        - trackCount: ì¸ê¸°ê³¡ ì„¹ì…˜ì— í‘œì‹œëœ ê³¡ ìˆ˜ (ì „ì²´ ì•„ë‹˜)
    """
    cache_key = f"artist_songs_playlist:{artist_id}:{country}"

    cached = cache_get(cache_key)
    if cached:
        return {"source": "cache", **cached}

    try:
        ytmusic = get_ytmusic(country)
        artist = ytmusic.get_artist(artist_id)

        if not artist:
            raise HTTPException(status_code=404, detail="Artist not found")

        artist_name = artist.get("name") or ""
        songs_section = artist.get("songs")

        if not songs_section or not isinstance(songs_section, dict):
            raise HTTPException(status_code=404, detail="Songs section not found")

        browse_id = songs_section.get("browseId")
        if not browse_id:
            raise HTTPException(status_code=404, detail="Songs playlist ID not found")

        # "VL" ì ‘ë‘ì‚¬ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ì¶”ì¶œ
        # ì˜ˆ: "VLOLAK5uy_xxx" -> "OLAK5uy_xxx"
        playlist_id = browse_id
        if browse_id.startswith("VL"):
            playlist_id = browse_id[2:]

        # ì¸ê¸°ê³¡ ìƒ˜í”Œ (ì²˜ìŒ ëª‡ ê°œ)
        top_songs = songs_section.get("results") or []

        result = {
            "playlistId": playlist_id,
            "browseId": browse_id,
            "artistId": artist_id,
            "artistName": artist_name,
            "trackCount": len(top_songs),
            "topSongs": [{
                "videoId": s.get("videoId"),
                "title": s.get("title"),
                "thumbnails": s.get("thumbnails", [])
            } for s in top_songs[:5] if isinstance(s, dict)]
        }

        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, result, ttl=3600)

        logger.info(f"Songs playlist extracted: {artist_name} -> {playlist_id}")
        return {"source": "api", **result}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Songs playlist error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# ì´ˆê³ ì† ê²€ìƒ‰ API (search()ë§Œ í˜¸ì¶œ, get_artist() ê±´ë„ˆë›°ê¸°)
# =============================================================================

@app.get("/api/search/quick")
async def search_quick(request: Request, q: str, country: str = None):
    """í†µí•© ê²€ìƒ‰ - ì•„í‹°ìŠ¤íŠ¸ + ì „ì²´ ì•¨ë²”/ì‹±ê¸€ + ì¸ê¸°ê³¡ 5ê°œ + ë¹„ìŠ·í•œ ì•„í‹°ìŠ¤íŠ¸ 10ëª…

    get_artist()ë¡œ ì „ì²´ ë””ìŠ¤ì½”ê·¸ë˜í”¼ ì¡°íšŒ.
    """
    if not q or len(q.strip()) < 1:
        raise HTTPException(status_code=400, detail="Query required")

    if not country:
        country = request.headers.get("CF-IPCountry", "US")

    cache_key = f"quick:{country}:{q.strip().lower()}"

    # 1. Redis ìºì‹œ í™•ì¸
    cached = cache_get(cache_key)
    if cached:
        cached["source"] = "cache"
        return cached

    # 2. ytmusicapi ê²€ìƒ‰ (search()ë§Œ í˜¸ì¶œ - ë¹ ë¦„!)
    # DB ìºì‹œ ì‚¬ìš© ì•ˆí•¨ - ì•¨ë²”/ë¹„ìŠ·í•œ ì•„í‹°ìŠ¤íŠ¸ë„ ë°˜í™˜í•´ì•¼ í•˜ë¯€ë¡œ
    try:
        ytmusic = get_ytmusic(country)

        # ë³‘ë ¬ë¡œ ì•„í‹°ìŠ¤íŠ¸, ë…¸ë˜ ê²€ìƒ‰ (ë¹„ìŠ·í•œ ì•„í‹°ìŠ¤íŠ¸ 10ëª… í¬í•¨)
        future_artists = run_in_thread(ytmusic.search, q.strip(), filter="artists", limit=11)
        future_songs = run_in_thread(ytmusic.search, q.strip(), filter="songs", limit=5)
        artists_results, songs_results = await asyncio.gather(future_artists, future_songs)

        artist_data = None
        similar_artists = []
        albums = []
        songs_playlist_id = None

        if artists_results and len(artists_results) > 0:
            artist = artists_results[0]
            artist_id = artist.get("browseId")

            # ì•„í‹°ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´ì—ì„œ ì „ì²´ ì•¨ë²”/ì‹±ê¸€ + í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ê°€ì ¸ì˜¤ê¸°
            if artist_id:
                try:
                    artist_detail = await run_in_thread(ytmusic.get_artist, artist_id)

                    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ì¶”ì¶œ
                    songs_section = artist_detail.get("songs", {})
                    if isinstance(songs_section, dict):
                        browse_id = songs_section.get("browseId")
                        if browse_id:
                            songs_playlist_id = browse_id[2:] if browse_id.startswith("VL") else browse_id

                    artist_name = artist.get("artist") or artist.get("name")

                    # ì „ì²´ ì•¨ë²” ê°€ì ¸ì˜¤ê¸° (get_artist_albums ì‚¬ìš©)
                    albums_section = artist_detail.get("albums", {})
                    if isinstance(albums_section, dict):
                        albums_browse_id = albums_section.get("browseId")
                        albums_params = albums_section.get("params")

                        if albums_browse_id and albums_params:
                            # ë” ë§ì€ ì•¨ë²”ì´ ìˆìŒ - ì „ì²´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                            try:
                                all_albums = await run_in_thread(
                                    ytmusic.get_artist_albums, albums_browse_id, albums_params
                                )
                                for album in (all_albums or []):
                                    albums.append({
                                        "browseId": album.get("browseId"),
                                        "title": album.get("title"),
                                        "artists": [{"name": artist_name}],
                                        "thumbnails": album.get("thumbnails", []),
                                        "year": album.get("year"),
                                        "type": "Album"
                                    })
                            except Exception as e:
                                logger.warning(f"Failed to get all albums: {e}")
                                # Fallback to initial results
                                for album in albums_section.get("results", []):
                                    albums.append({
                                        "browseId": album.get("browseId"),
                                        "title": album.get("title"),
                                        "artists": [{"name": artist_name}],
                                        "thumbnails": album.get("thumbnails", []),
                                        "year": album.get("year"),
                                        "type": "Album"
                                    })
                        else:
                            # browseId/params ì—†ìœ¼ë©´ ì´ˆê¸° ê²°ê³¼ ì‚¬ìš©
                            for album in albums_section.get("results", []):
                                albums.append({
                                    "browseId": album.get("browseId"),
                                    "title": album.get("title"),
                                    "artists": [{"name": artist_name}],
                                    "thumbnails": album.get("thumbnails", []),
                                    "year": album.get("year"),
                                    "type": "Album"
                                })

                    # ì „ì²´ ì‹±ê¸€ ê°€ì ¸ì˜¤ê¸° (get_artist_albums ì‚¬ìš©)
                    singles_section = artist_detail.get("singles", {})
                    if isinstance(singles_section, dict):
                        singles_browse_id = singles_section.get("browseId")
                        singles_params = singles_section.get("params")

                        if singles_browse_id and singles_params:
                            # ë” ë§ì€ ì‹±ê¸€ì´ ìˆìŒ - ì „ì²´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                            try:
                                all_singles = await run_in_thread(
                                    ytmusic.get_artist_albums, singles_browse_id, singles_params
                                )
                                for single in (all_singles or []):
                                    albums.append({
                                        "browseId": single.get("browseId"),
                                        "title": single.get("title"),
                                        "artists": [{"name": artist_name}],
                                        "thumbnails": single.get("thumbnails", []),
                                        "year": single.get("year"),
                                        "type": "Single"
                                    })
                            except Exception as e:
                                logger.warning(f"Failed to get all singles: {e}")
                                # Fallback to initial results
                                for single in singles_section.get("results", []):
                                    albums.append({
                                        "browseId": single.get("browseId"),
                                        "title": single.get("title"),
                                        "artists": [{"name": artist_name}],
                                        "thumbnails": single.get("thumbnails", []),
                                        "year": single.get("year"),
                                        "type": "Single"
                                    })
                        else:
                            # browseId/params ì—†ìœ¼ë©´ ì´ˆê¸° ê²°ê³¼ ì‚¬ìš©
                            for single in singles_section.get("results", []):
                                albums.append({
                                    "browseId": single.get("browseId"),
                                    "title": single.get("title"),
                                    "artists": [{"name": artist_name}],
                                    "thumbnails": single.get("thumbnails", []),
                                    "year": single.get("year"),
                                    "type": "Single"
                                })

                    # get_artist()ì˜ related ì„¹ì…˜ì—ì„œ ë¹„ìŠ·í•œ ì•„í‹°ìŠ¤íŠ¸ ì¶”ì¶œ
                    related_section = artist_detail.get("related", {})
                    if isinstance(related_section, dict):
                        for ra in related_section.get("results", []):
                            if len(similar_artists) >= 10:
                                break
                            ra_id = ra.get("browseId")
                            if ra_id and ra_id != artist_id:
                                similar_artists.append({
                                    "browseId": ra_id,
                                    "name": ra.get("title") or ra.get("name"),
                                    "thumbnail": get_best_thumbnail(ra.get("thumbnails", []))
                                })
                except Exception as e:
                    logger.warning(f"Failed to get artist detail: {e}")

            artist_data = {
                "browseId": artist_id,
                "name": artist.get("artist") or artist.get("name"),
                "thumbnail": get_best_thumbnail(artist.get("thumbnails", [])),
                "songsPlaylistId": songs_playlist_id
            }

            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ê°€ ë¹„ìŠ·í•œ ì•„í‹°ìŠ¤íŠ¸ (10ëª… ë¯¸ë§Œì¼ ê²½ìš°)
            for a in artists_results[1:11]:
                if len(similar_artists) >= 10:
                    break
                a_id = a.get("browseId")
                if a_id and not any(s.get("browseId") == a_id for s in similar_artists):
                    similar_artists.append({
                        "browseId": a_id,
                        "name": a.get("artist") or a.get("name"),
                        "thumbnail": get_best_thumbnail(a.get("thumbnails", []))
                    })

            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ DBì— ì €ì¥ + ê°€ìƒíšŒì› ìë™ ìƒì„±
            if supabase_client and artist_data.get("browseId"):
                try:
                    browse_id = artist_data["browseId"]
                    artist_name = artist_data["name"]
                    thumbnail_url = artist_data["thumbnail"]

                    supabase_client.table("music_artists").upsert({
                        "browse_id": browse_id,
                        "name": artist_name,
                        "thumbnail_url": thumbnail_url,
                        "songs_playlist_id": songs_playlist_id,
                        "updated_at": datetime.now(timezone.utc).isoformat()
                    }, on_conflict="browse_id").execute()

                    # ê°€ìƒíšŒì› ìë™ ìƒì„±
                    try:
                        existing = supabase_client.table("profiles").select("id").eq("artist_browse_id", browse_id).execute()
                        if not existing.data or len(existing.data) == 0:
                            create_virtual_member_sync(browse_id, artist_name, thumbnail_url)
                            logger.info(f"Virtual member auto-created via search: {artist_name}")
                    except Exception as vm_error:
                        logger.warning(f"Virtual member auto-creation skipped: {vm_error}")
                except Exception:
                    pass

        # ë…¸ë˜ ê²°ê³¼ ì •ë¦¬
        songs = []
        for s in (songs_results or [])[:5]:
            songs.append({
                "videoId": s.get("videoId"),
                "title": s.get("title"),
                "artists": s.get("artists", []),
                "thumbnails": s.get("thumbnails", []),
                "duration": s.get("duration"),
                "album": s.get("album")
            })

        # ì•¨ë²”ì€ ìœ„ì—ì„œ get_artist()ë¡œ ì´ë¯¸ ì¶”ì¶œë¨ (ì „ì²´ ì•¨ë²” + ì‹±ê¸€)

        response = {
            "artist": artist_data,
            "songs": songs,
            "albums": albums,
            "similarArtists": similar_artists,
            "source": "api"
        }

        cache_set(cache_key, response, ttl=1800)
        return response

    except Exception as e:
        logger.error(f"Quick search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/artist/playlist-id")
async def get_artist_playlist_id(q: str, country: str = "US"):
    """ì•„í‹°ìŠ¤íŠ¸ ê²€ìƒ‰ -> í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë§Œ ë°˜í™˜ (ì´ˆê³ ì† ì—”ë“œí¬ì¸íŠ¸)

    1. Supabaseì—ì„œ ë¨¼ì € ê²€ìƒ‰ (ìºì‹œ)
    2. ì—†ìœ¼ë©´ ytmusicapi í˜¸ì¶œ í›„ Supabaseì— ì €ì¥
    """
    if not q or len(q.strip()) < 1:
        raise HTTPException(status_code=400, detail="Query required")

    try:
        # 1. Supabaseì—ì„œ ë¨¼ì € ê²€ìƒ‰ (ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰)
        if supabase_client:
            try:
                result = supabase_client.table("music_artists").select(
                    "browse_id, name, songs_playlist_id"
                ).ilike("name", f"%{q.strip()}%").limit(1).execute()

                if result.data and result.data[0].get("songs_playlist_id"):
                    cached = result.data[0]
                    logger.info(f"[playlist-id] DB hit: {cached['name']}")
                    return {
                        "playlistId": cached["songs_playlist_id"],
                        "artist": cached["name"],
                        "source": "database"
                    }
            except Exception as db_err:
                logger.warning(f"DB search error: {db_err}")

        # 2. DBì— ì—†ìœ¼ë©´ ytmusicapi í˜¸ì¶œ
        ytmusic = get_ytmusic(country)
        artists = await run_in_thread(ytmusic.search, q.strip(), filter="artists", limit=1)

        if not artists:
            return {"playlistId": None, "artist": None}

        artist = artists[0]
        artist_id = artist.get("browseId")
        artist_name = artist.get("artist") or artist.get("name")

        if not artist_id:
            return {"playlistId": None, "artist": artist_name}

        # 3. ì•„í‹°ìŠ¤íŠ¸ ìƒì„¸ì—ì„œ songs.browseIdë§Œ ì¶”ì¶œ
        artist_detail = await run_in_thread(ytmusic.get_artist, artist_id)

        songs_section = artist_detail.get("songs", {})
        songs_browse_id = songs_section.get("browseId") if isinstance(songs_section, dict) else None

        # VL ì œê±° -> ìˆœìˆ˜ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID
        playlist_id = None
        if songs_browse_id:
            playlist_id = songs_browse_id[2:] if songs_browse_id.startswith("VL") else songs_browse_id

        # 4. Supabaseì— ì €ì¥ (ì¬ê²€ìƒ‰ ì‹œ ë¹ ë¥¸ ì‘ë‹µ)
        if supabase_client and playlist_id:
            try:
                supabase_client.table("music_artists").upsert({
                    "browse_id": artist_id,
                    "name": artist_name,
                    "songs_playlist_id": playlist_id,
                    "thumbnail_url": get_best_thumbnail(artist.get("thumbnails", [])),
                    "updated_at": datetime.now(timezone.utc).isoformat()
                }, on_conflict="browse_id").execute()
                logger.info(f"[playlist-id] Saved to DB: {artist_name} -> {playlist_id}")
            except Exception as save_err:
                logger.warning(f"DB save error: {save_err}")

        return {
            "playlistId": playlist_id,
            "artist": artist_name,
            "source": "api"
        }

    except Exception as e:
        logger.error(f"Playlist ID search error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/artist/{artist_id}")
async def get_artist(artist_id: str, country: str = "US", force_refresh: bool = False):
    """ì•„í‹°ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´"""
    cache_key = f"artist:{artist_id}:{country}"

    if not force_refresh:
        cached = cache_get(cache_key)
        if cached:
            return {"source": "cache", "artist": cached}

    try:
        ytmusic = get_ytmusic(country)
        artist = ytmusic.get_artist(artist_id)

        # 6ì‹œê°„ ìºì‹œ
        cache_set(cache_key, artist, ttl=21600)

        return {"source": "api", "artist": artist}
    except Exception as e:
        logger.error(f"Artist error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/artist/{artist_id}/albums")
async def get_artist_all_albums(artist_id: str, country: str = "US"):
    """
    ì•„í‹°ìŠ¤íŠ¸ì˜ ì „ì²´ ì•¨ë²” ëª©ë¡ (ì•¨ë²” + ì‹±ê¸€)
    - ê²€ìƒ‰ ê²°ê³¼ì—ì„œëŠ” ìƒ˜í”Œë§Œ ë°˜í™˜
    - ì´ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì „ì²´ ëª©ë¡ ë°˜í™˜
    """
    cache_key = f"artist_albums:{artist_id}:{country}"

    cached = cache_get(cache_key)
    if cached:
        return {"source": "cache", "albums": cached}

    try:
        ytmusic = get_ytmusic(country)
        artist = ytmusic.get_artist(artist_id)

        if not artist:
            raise HTTPException(status_code=404, detail="Artist not found")

        all_albums = []

        # ì „ì²´ ì•¨ë²” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        albums_section = artist.get("albums")
        if albums_section and isinstance(albums_section, dict):
            params = albums_section.get("params")
            browse_id = albums_section.get("browseId")

            if params and browse_id:
                try:
                    full_albums = ytmusic.get_artist_albums(browse_id, params) or []
                    for album in full_albums:
                        if isinstance(album, dict) and album.get("browseId"):
                            all_albums.append({
                                "browseId": album.get("browseId"),
                                "title": album.get("title") or "",
                                "type": album.get("type") or "Album",
                                "year": album.get("year") or "",
                                "thumbnails": album.get("thumbnails") or []
                            })
                except Exception as e:
                    logger.warning(f"get_artist_albums error: {e}")
                    # ìƒ˜í”Œ ëª©ë¡ì´ë¼ë„ ë°˜í™˜
                    for album in albums_section.get("results") or []:
                        if isinstance(album, dict) and album.get("browseId"):
                            all_albums.append({
                                "browseId": album.get("browseId"),
                                "title": album.get("title") or "",
                                "type": album.get("type") or "Album",
                                "year": album.get("year") or "",
                                "thumbnails": album.get("thumbnails") or []
                            })

        # ì „ì²´ ì‹±ê¸€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        singles_section = artist.get("singles")
        if singles_section and isinstance(singles_section, dict):
            params = singles_section.get("params")
            browse_id = singles_section.get("browseId")

            if params and browse_id:
                try:
                    full_singles = ytmusic.get_artist_albums(browse_id, params) or []
                    for single in full_singles:
                        if isinstance(single, dict) and single.get("browseId"):
                            all_albums.append({
                                "browseId": single.get("browseId"),
                                "title": single.get("title") or "",
                                "type": "Single",
                                "year": single.get("year") or "",
                                "thumbnails": single.get("thumbnails") or []
                            })
                except Exception as e:
                    logger.warning(f"get_artist_albums for singles error: {e}")
                    for single in singles_section.get("results") or []:
                        if isinstance(single, dict) and single.get("browseId"):
                            all_albums.append({
                                "browseId": single.get("browseId"),
                                "title": single.get("title") or "",
                                "type": "Single",
                                "year": single.get("year") or "",
                                "thumbnails": single.get("thumbnails") or []
                            })

        # 1ì‹œê°„ ìºì‹œ
        cache_set(cache_key, all_albums, ttl=3600)

        return {"source": "api", "albums": all_albums, "count": len(all_albums)}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Artist albums error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ì•¨ë²” ì •ë³´ API
# =============================================================================

@app.get("/api/album/{album_id}")
async def get_album(album_id: str, country: str = "US"):
    """
    ì•¨ë²” ìƒì„¸ ì •ë³´ (íŠ¸ë™ í¬í•¨) - ì˜¨ë””ë§¨ë“œ ë¡œë“œ
    1. DBì—ì„œ íŠ¸ë™ì´ ìˆëŠ”ì§€ í™•ì¸
    2. ì—†ìœ¼ë©´ ytmusicapiì—ì„œ ê°€ì ¸ì™€ì„œ DBì— ì €ì¥
    """
    cache_key = f"album:{album_id}:{country}"

    # Redis ìºì‹œ í™•ì¸
    cached = cache_get(cache_key)
    if cached:
        return {"source": "cache", "album": cached}

    # DBì—ì„œ íŠ¸ë™ í™•ì¸
    if supabase_client:
        try:
            tracks_result = supabase_client.table("music_tracks").select("*").eq(
                "album_browse_id", album_id
            ).order("track_number").execute()

            if tracks_result.data and len(tracks_result.data) > 0:
                # DBì— íŠ¸ë™ì´ ìˆìŒ - ì•¨ë²” ë©”íƒ€ë°ì´í„°ë„ ê°€ì ¸ì˜¤ê¸°
                album_result = supabase_client.table("music_albums").select("*").eq(
                    "browse_id", album_id
                ).single().execute()

                if album_result.data:
                    album_data = {
                        "browseId": album_result.data.get("browse_id"),
                        "title": album_result.data.get("title"),
                        "type": album_result.data.get("type"),
                        "year": album_result.data.get("year"),
                        "thumbnails": [{"url": album_result.data.get("thumbnail_url")}] if album_result.data.get("thumbnail_url") else [],
                        "tracks": [{
                            "videoId": t.get("video_id"),
                            "title": t.get("title"),
                            "duration": t.get("duration"),
                            "trackNumber": t.get("track_number"),
                            "thumbnails": [{"url": t.get("thumbnail_url")}] if t.get("thumbnail_url") else [],
                            "isExplicit": t.get("is_explicit", False)
                        } for t in tracks_result.data]
                    }

                    # Redisì— ìºì‹œ
                    cache_set(cache_key, album_data, ttl=21600)

                    logger.info(f"Album from DB: {album_id} ({len(tracks_result.data)} tracks)")
                    return {"source": "database", "album": album_data}
        except Exception as e:
            logger.warning(f"DB album fetch error: {e}")

    # ytmusicapiì—ì„œ ê°€ì ¸ì˜¤ê¸°
    try:
        ytmusic = get_ytmusic(country)
        album = ytmusic.get_album(album_id)

        if album and supabase_client:
            # DBì— íŠ¸ë™ ì €ì¥
            tracks = album.get("tracks") or []
            artist_browse_id = None

            # ì•„í‹°ìŠ¤íŠ¸ ID ì¶”ì¶œ
            artists = album.get("artists") or []
            if artists and isinstance(artists, list) and len(artists) > 0:
                artist_browse_id = artists[0].get("id") or artists[0].get("browseId")

            # ì•¨ë²” ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (íŠ¸ë™ ìˆ˜ í¬í•¨)
            try:
                album_update = {
                    "browse_id": album_id,
                    "title": album.get("title") or "",
                    "type": album.get("type") or "Album",
                    "year": album.get("year") or "",
                    "thumbnail_url": get_best_thumbnail(album.get("thumbnails", [])),
                    "track_count": len(tracks)
                }
                if artist_browse_id:
                    album_update["artist_browse_id"] = artist_browse_id

                supabase_client.table("music_albums").upsert(
                    album_update, on_conflict="browse_id"
                ).execute()
            except Exception as e:
                logger.warning(f"Album metadata update error: {e}")

            # íŠ¸ë™ ì €ì¥
            for idx, track in enumerate(tracks):
                if not isinstance(track, dict):
                    continue
                video_id = track.get("videoId")
                if not video_id:
                    continue

                try:
                    track_data = {
                        "video_id": video_id,
                        "album_browse_id": album_id,
                        "artist_browse_id": artist_browse_id,
                        "title": track.get("title") or "",
                        "duration": track.get("duration") or "",
                        "track_number": idx + 1,
                        "thumbnail_url": get_best_thumbnail(track.get("thumbnails") or album.get("thumbnails", [])),
                        "is_explicit": track.get("isExplicit", False)
                    }

                    supabase_client.table("music_tracks").upsert(
                        track_data, on_conflict="video_id"
                    ).execute()
                except Exception as e:
                    logger.warning(f"Track save error: {e}")

            logger.info(f"Album tracks saved to DB: {album_id} ({len(tracks)} tracks)")

        # íŠ¸ë™ì— ì¸ë„¤ì¼ì´ ì—†ìœ¼ë©´ ì•¨ë²” ì¸ë„¤ì¼ ì¶”ê°€
        album_thumbnails = album.get("thumbnails", [])
        for track in album.get("tracks", []):
            if not track.get("thumbnails") and album_thumbnails:
                track["thumbnails"] = album_thumbnails

        return {"source": "api", "album": album}
    except Exception as e:
        logger.error(f"Album error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì •ë³´ API
# =============================================================================

@app.get("/api/playlist/{playlist_id}")
async def get_playlist(playlist_id: str, country: str = "US", limit: int = None):
    """í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´ (íŠ¸ë™ ëª©ë¡ í¬í•¨) - limit=Noneì´ë©´ ì „ì²´ íŠ¸ë™"""
    cache_key = f"playlist:{playlist_id}:{country}:{limit or 'all'}"

    cached = cache_get(cache_key)
    if cached:
        return {"source": "cache", "playlist": cached}

    try:
        ytmusic = get_ytmusic(country)
        # limit=Noneì´ë©´ ì „ì²´ íŠ¸ë™ì„ ê°€ì ¸ì˜´
        playlist = ytmusic.get_playlist(playlist_id, limit=limit)

        # íŠ¸ë™ì— ì¸ë„¤ì¼ì´ ì—†ìœ¼ë©´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¸ë„¤ì¼ ì¶”ê°€
        playlist_thumbnails = playlist.get("thumbnails", [])
        for track in playlist.get("tracks", []):
            if not track.get("thumbnails") and playlist_thumbnails:
                track["thumbnails"] = playlist_thumbnails

        return {"source": "api", "playlist": playlist}
    except Exception as e:
        logger.error(f"Playlist error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# ìºì‹œ ê´€ë¦¬ API
# =============================================================================

@app.delete("/api/cache/clear")
async def clear_search_cache(secret: str = None):
    """ê²€ìƒ‰ ìºì‹œ ì „ì²´ ì‚­ì œ (Supabase music_search_cache í…Œì´ë¸”)"""
    # ê°„ë‹¨í•œ ë³´ì•ˆ ì²´í¬ (í”„ë¡œë•ì…˜ì—ì„œëŠ” ë” ê°•ë ¥í•œ ì¸ì¦ í•„ìš”)
    admin_secret = os.getenv("ADMIN_SECRET", "sori-admin-2024")
    if secret != admin_secret:
        raise HTTPException(status_code=403, detail="Unauthorized")

    if not supabase_client:
        raise HTTPException(status_code=500, detail="Supabase not configured")

    try:
        # music_search_cache í…Œì´ë¸” ì „ì²´ ì‚­ì œ
        result = supabase_client.table("music_search_cache").delete().neq("id", "00000000-0000-0000-0000-000000000000").execute()

        # ë©”ëª¨ë¦¬ ìºì‹œë„ í´ë¦¬ì–´
        global memory_cache
        memory_cache = {}

        deleted_count = len(result.data) if result.data else 0
        logger.info(f"Cleared {deleted_count} cache entries")

        return {
            "status": "success",
            "message": f"Cleared {deleted_count} cache entries",
            "deleted_count": deleted_count
        }
    except Exception as e:
        logger.error(f"Cache clear error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/admin/run-sql")
async def run_custom_sql(secret: str = None, access_token: str = None, sql: str = None):
    """ì„ì˜ì˜ SQL ì‹¤í–‰ - Management API ì‚¬ìš©"""
    import httpx

    admin_secret = os.getenv("ADMIN_SECRET", "sori-admin-2024")
    if secret != admin_secret:
        raise HTTPException(status_code=403, detail="Unauthorized")

    if not sql:
        raise HTTPException(status_code=400, detail="sql parameter required")

    mgmt_token = access_token or os.getenv("SUPABASE_ACCESS_TOKEN")
    if not mgmt_token:
        raise HTTPException(status_code=400, detail=ERROR_ACCESS_TOKEN_REQUIRED)

    project_ref = "nrtkbulkzhhlstaomvas"

    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            f"https://api.supabase.com/v1/projects/{project_ref}/database/query",
            headers={
                "Authorization": f"Bearer {mgmt_token}",
                "Content-Type": "application/json"
            },
            json={"query": sql}
        )

        if response.status_code != 201:
            return {"success": False, "error": response.text, "status": response.status_code}

        return {"success": True, "result": response.json()}


@app.post("/api/admin/fix-notification-triggers")
async def fix_notification_triggers(secret: str = None, access_token: str = None):
    """ì•Œë¦¼ íŠ¸ë¦¬ê±° ìˆ˜ì • - posts í…Œì´ë¸”ìš©"""
    import httpx

    admin_secret = os.getenv("ADMIN_SECRET", "sori-admin-2024")
    if secret != admin_secret:
        raise HTTPException(status_code=403, detail="Unauthorized")

    mgmt_token = access_token or os.getenv("SUPABASE_ACCESS_TOKEN")
    if not mgmt_token:
        raise HTTPException(status_code=400, detail=ERROR_ACCESS_TOKEN_REQUIRED)

    project_ref = "nrtkbulkzhhlstaomvas"

    sql_commands = [
        # Fix like notification trigger
        """CREATE OR REPLACE FUNCTION create_post_like_notification()
RETURNS TRIGGER AS $$
DECLARE
    post_owner_id UUID;
BEGIN
    SELECT user_id INTO post_owner_id FROM posts WHERE id = NEW.post_id;
    IF post_owner_id IS NOT NULL AND post_owner_id != NEW.user_id THEN
        INSERT INTO notifications (user_id, actor_id, type, reference_id, reference_type, content)
        VALUES (post_owner_id, NEW.user_id, 'like', NEW.post_id, 'post', 'liked your post');
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER""",

        # Fix comment notification trigger
        """CREATE OR REPLACE FUNCTION create_post_comment_notification()
RETURNS TRIGGER AS $$
DECLARE
    post_owner_id UUID;
BEGIN
    SELECT user_id INTO post_owner_id FROM posts WHERE id = NEW.post_id;
    IF post_owner_id IS NOT NULL AND post_owner_id != NEW.user_id THEN
        INSERT INTO notifications (user_id, actor_id, type, reference_id, reference_type, content)
        VALUES (post_owner_id, NEW.user_id, 'comment', NEW.post_id, 'post', 'commented on your post');
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER""",

        # Recreate triggers
        "DROP TRIGGER IF EXISTS on_post_like_notify ON post_likes",
        """CREATE TRIGGER on_post_like_notify
    AFTER INSERT ON post_likes
    FOR EACH ROW EXECUTE FUNCTION create_post_like_notification()""",

        "DROP TRIGGER IF EXISTS on_post_comment_notify ON post_comments",
        """CREATE TRIGGER on_post_comment_notify
    AFTER INSERT ON post_comments
    FOR EACH ROW EXECUTE FUNCTION create_post_comment_notification()"""
    ]

    results = []
    async with httpx.AsyncClient(timeout=30.0) as client:
        for i, sql in enumerate(sql_commands):
            response = await client.post(
                f"https://api.supabase.com/v1/projects/{project_ref}/database/query",
                headers={
                    "Authorization": f"Bearer {mgmt_token}",
                    "Content-Type": "application/json"
                },
                json={"query": sql}
            )

            results.append({
                "index": i,
                "success": response.status_code == 201,
                "status": response.status_code,
                "error": response.text if response.status_code != 201 else None
            })

    return {"results": results, "total": len(sql_commands), "success": all(r["success"] for r in results)}


@app.post("/api/admin/fix-advisor")
async def fix_advisor_warnings(secret: str = None, access_token: str = None):
    """Supabase Advisor ê²½ê³  ìˆ˜ì • - Management APIë¡œ SQL ì‹¤í–‰"""
    import httpx

    admin_secret = os.getenv("ADMIN_SECRET", "sori-admin-2024")
    if secret != admin_secret:
        raise HTTPException(status_code=403, detail="Unauthorized")

    # Supabase Management API í† í° (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” íŒŒë¼ë¯¸í„°)
    mgmt_token = access_token or os.getenv("SUPABASE_ACCESS_TOKEN")
    if not mgmt_token:
        raise HTTPException(status_code=400, detail=ERROR_ACCESS_TOKEN_REQUIRED)

    project_ref = "nrtkbulkzhhlstaomvas"

    # SQL ëª…ë ¹ì–´ë“¤ (í•˜ë‚˜ì”© ì‹¤í–‰)
    sql_commands = [
        "DROP TABLE IF EXISTS music_tracks CASCADE",
        "DROP TABLE IF EXISTS music_albums CASCADE",
        "DROP TABLE IF EXISTS music_artists CASCADE",
        "DROP TABLE IF EXISTS artist_relations CASCADE",
        "DROP FUNCTION IF EXISTS search_music_artists(text, integer)",
        "DROP FUNCTION IF EXISTS get_artist_full_data(text)",
        "DROP FUNCTION IF EXISTS normalize_music_text() CASCADE",
        'DROP POLICY IF EXISTS "Users can insert their own profile." ON profiles',
        'DROP POLICY IF EXISTS "Users can update own profile." ON profiles',
        'CREATE POLICY "Users can insert their own profile." ON profiles FOR INSERT WITH CHECK ((select auth.uid()) = id)',
        'CREATE POLICY "Users can update own profile." ON profiles FOR UPDATE USING ((select auth.uid()) = id)',
        'DROP POLICY IF EXISTS "Users can insert their own playlists." ON playlists',
        'DROP POLICY IF EXISTS "Users can update their own playlists." ON playlists',
        'CREATE POLICY "Users can insert their own playlists." ON playlists FOR INSERT WITH CHECK ((select auth.uid()) = user_id)',
        'CREATE POLICY "Users can update their own playlists." ON playlists FOR UPDATE USING ((select auth.uid()) = user_id)',
        'DROP POLICY IF EXISTS "Search cache is viewable by everyone" ON music_search_cache',
        'DROP POLICY IF EXISTS "Service role can manage music_search_cache" ON music_search_cache',
        'CREATE POLICY "Public read access" ON music_search_cache FOR SELECT USING (true)',
        "CREATE SCHEMA IF NOT EXISTS extensions",
        "DROP EXTENSION IF EXISTS pg_trgm",
        "CREATE EXTENSION IF NOT EXISTS pg_trgm SCHEMA extensions",
        """CREATE OR REPLACE FUNCTION public.handle_new_user()
RETURNS trigger LANGUAGE plpgsql SECURITY DEFINER SET search_path = public AS $$
BEGIN
  INSERT INTO public.profiles (id, full_name, avatar_url)
  VALUES (new.id, new.raw_user_meta_data->>'full_name', new.raw_user_meta_data->>'avatar_url');
  RETURN new;
END;
$$"""
    ]

    results = []

    async with httpx.AsyncClient(timeout=30.0) as client:
        for sql in sql_commands:
            try:
                response = await client.post(
                    f"https://api.supabase.com/v1/projects/{project_ref}/database/query",
                    headers={
                        "Authorization": f"Bearer {mgmt_token}",
                        "Content-Type": "application/json"
                    },
                    json={"query": sql}
                )

                if response.status_code == 201 or response.status_code == 200:
                    results.append({"sql": sql[:50] + "...", "status": "success"})
                else:
                    results.append({"sql": sql[:50] + "...", "status": "error", "code": response.status_code, "error": response.text})

            except Exception as e:
                results.append({"sql": sql[:50] + "...", "status": "error", "error": str(e)})

    success_count = len([r for r in results if r["status"] == "success"])
    return {
        "status": "completed",
        "message": f"{success_count}/{len(sql_commands)} commands executed",
        "results": results
    }


@app.post("/api/admin/run-migrations")
async def run_migrations(secret: str = None, access_token: str = None):
    """SNS ê¸°ëŠ¥ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ - follows, likes, stories, messages, hashtags, reposts, comments, notifications"""
    import httpx

    admin_secret = os.getenv("ADMIN_SECRET", "sori-admin-2024")
    if secret != admin_secret:
        raise HTTPException(status_code=403, detail="Unauthorized")

    mgmt_token = access_token or os.getenv("SUPABASE_ACCESS_TOKEN")
    if not mgmt_token:
        raise HTTPException(status_code=400, detail=ERROR_ACCESS_TOKEN_REQUIRED)

    project_ref = "nrtkbulkzhhlstaomvas"

    sql_commands = [
        # =====================================================
        # FOLLOWS TABLE - íŒ”ë¡œìš° ì‹œìŠ¤í…œ
        # =====================================================
        """CREATE TABLE IF NOT EXISTS follows (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            follower_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            following_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(follower_id, following_id),
            CHECK (follower_id != following_id)
        )""",
        "ALTER TABLE follows ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Anyone can view follows" ON follows',
        """CREATE POLICY "Anyone can view follows" ON follows FOR SELECT USING (true)""",
        'DROP POLICY IF EXISTS "Users can follow others" ON follows',
        """CREATE POLICY "Users can follow others" ON follows FOR INSERT WITH CHECK (auth.uid() = follower_id)""",
        'DROP POLICY IF EXISTS "Users can unfollow" ON follows',
        """CREATE POLICY "Users can unfollow" ON follows FOR DELETE USING (auth.uid() = follower_id)""",
        "CREATE INDEX IF NOT EXISTS idx_follows_follower ON follows(follower_id)",
        "CREATE INDEX IF NOT EXISTS idx_follows_following ON follows(following_id)",

        # Profiles - followers/following count columns
        "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS followers_count INTEGER DEFAULT 0",
        "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS following_count INTEGER DEFAULT 0",
        "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS bio TEXT",
        "ALTER TABLE profiles ADD COLUMN IF NOT EXISTS created_at TIMESTAMPTZ DEFAULT NOW()",

        # Follow count trigger function
        """CREATE OR REPLACE FUNCTION update_follow_counts()
        RETURNS TRIGGER AS $$
        BEGIN
            IF TG_OP = 'INSERT' THEN
                UPDATE profiles SET followers_count = followers_count + 1 WHERE id = NEW.following_id;
                UPDATE profiles SET following_count = following_count + 1 WHERE id = NEW.follower_id;
                RETURN NEW;
            ELSIF TG_OP = 'DELETE' THEN
                UPDATE profiles SET followers_count = GREATEST(0, followers_count - 1) WHERE id = OLD.following_id;
                UPDATE profiles SET following_count = GREATEST(0, following_count - 1) WHERE id = OLD.follower_id;
                RETURN OLD;
            END IF;
            RETURN NULL;
        END;
        $$ LANGUAGE plpgsql SECURITY DEFINER""",
        "DROP TRIGGER IF EXISTS on_follow_change ON follows",
        """CREATE TRIGGER on_follow_change
            AFTER INSERT OR DELETE ON follows
            FOR EACH ROW EXECUTE FUNCTION update_follow_counts()""",

        # =====================================================
        # LIKES TABLE - ì¢‹ì•„ìš” ì‹œìŠ¤í…œ
        # =====================================================
        """CREATE TABLE IF NOT EXISTS likes (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            post_id UUID NOT NULL REFERENCES playlists(id) ON DELETE CASCADE,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(user_id, post_id)
        )""",
        "ALTER TABLE likes ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Anyone can view likes" ON likes',
        """CREATE POLICY "Anyone can view likes" ON likes FOR SELECT USING (true)""",
        'DROP POLICY IF EXISTS "Users can like posts" ON likes',
        """CREATE POLICY "Users can like posts" ON likes FOR INSERT WITH CHECK (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "Users can unlike posts" ON likes',
        """CREATE POLICY "Users can unlike posts" ON likes FOR DELETE USING (auth.uid() = user_id)""",
        "CREATE INDEX IF NOT EXISTS idx_likes_user ON likes(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_likes_post ON likes(post_id)",

        # Playlists - like_count column
        "ALTER TABLE playlists ADD COLUMN IF NOT EXISTS like_count INTEGER DEFAULT 0",

        # Like count trigger function
        """CREATE OR REPLACE FUNCTION update_like_counts()
        RETURNS TRIGGER AS $$
        BEGIN
            IF TG_OP = 'INSERT' THEN
                UPDATE playlists SET like_count = like_count + 1 WHERE id = NEW.post_id;
                RETURN NEW;
            ELSIF TG_OP = 'DELETE' THEN
                UPDATE playlists SET like_count = GREATEST(0, like_count - 1) WHERE id = OLD.post_id;
                RETURN OLD;
            END IF;
            RETURN NULL;
        END;
        $$ LANGUAGE plpgsql SECURITY DEFINER""",
        "DROP TRIGGER IF EXISTS on_like_change ON likes",
        """CREATE TRIGGER on_like_change
            AFTER INSERT OR DELETE ON likes
            FOR EACH ROW EXECUTE FUNCTION update_like_counts()""",

        # =====================================================
        # CONVERSATIONS TABLES (must be created before messages can reference them)
        # =====================================================
        """CREATE TABLE IF NOT EXISTS conversations (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        """CREATE TABLE IF NOT EXISTS conversation_participants (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            last_read_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(conversation_id, user_id)
        )""",
        """CREATE TABLE IF NOT EXISTS messages (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
            sender_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            content TEXT NOT NULL,
            shared_track_id TEXT,
            shared_track_title TEXT,
            shared_track_artist TEXT,
            shared_track_thumbnail TEXT,
            created_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        "ALTER TABLE conversations ENABLE ROW LEVEL SECURITY",
        "ALTER TABLE conversation_participants ENABLE ROW LEVEL SECURITY",
        "ALTER TABLE messages ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Users can view own conversations" ON conversations',
        """CREATE POLICY "Users can view own conversations" ON conversations FOR SELECT USING (
            EXISTS (SELECT 1 FROM conversation_participants WHERE conversation_id = id AND user_id = auth.uid())
        )""",
        'DROP POLICY IF EXISTS "Users can create conversations" ON conversations',
        """CREATE POLICY "Users can create conversations" ON conversations FOR INSERT WITH CHECK (true)""",
        'DROP POLICY IF EXISTS "Users can view own participations" ON conversation_participants',
        """CREATE POLICY "Users can view own participations" ON conversation_participants FOR SELECT USING (
            EXISTS (SELECT 1 FROM conversation_participants cp WHERE cp.conversation_id = conversation_id AND cp.user_id = auth.uid())
        )""",
        'DROP POLICY IF EXISTS "Users can create participations" ON conversation_participants',
        """CREATE POLICY "Users can create participations" ON conversation_participants FOR INSERT WITH CHECK (true)""",
        'DROP POLICY IF EXISTS "Users can update own participation" ON conversation_participants',
        """CREATE POLICY "Users can update own participation" ON conversation_participants FOR UPDATE USING (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "Users can view messages in own conversations" ON messages',
        """CREATE POLICY "Users can view messages in own conversations" ON messages FOR SELECT USING (
            EXISTS (SELECT 1 FROM conversation_participants WHERE conversation_id = messages.conversation_id AND user_id = auth.uid())
        )""",
        'DROP POLICY IF EXISTS "Users can send messages" ON messages',
        """CREATE POLICY "Users can send messages" ON messages FOR INSERT WITH CHECK (auth.uid() = sender_id)""",
        "CREATE INDEX IF NOT EXISTS idx_messages_conversation ON messages(conversation_id)",
        "CREATE INDEX IF NOT EXISTS idx_conversation_participants_user ON conversation_participants(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_conversation_participants_conv ON conversation_participants(conversation_id)",

        # =====================================================
        # STORIES TABLE
        # =====================================================
        # Stories table
        """CREATE TABLE IF NOT EXISTS stories (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            content_type TEXT NOT NULL CHECK (content_type IN ('track', 'playlist', 'text')),
            video_id TEXT,
            playlist_id UUID REFERENCES playlists(id) ON DELETE SET NULL,
            title TEXT,
            artist TEXT,
            cover_url TEXT,
            text_content TEXT,
            background_color TEXT DEFAULT '#000000',
            created_at TIMESTAMPTZ DEFAULT NOW(),
            expires_at TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '24 hours'),
            is_active BOOLEAN DEFAULT TRUE
        )""",
        # Story views
        """CREATE TABLE IF NOT EXISTS story_views (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            story_id UUID NOT NULL REFERENCES stories(id) ON DELETE CASCADE,
            viewer_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            viewed_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(story_id, viewer_id)
        )""",
        # Stories RLS
        "ALTER TABLE stories ENABLE ROW LEVEL SECURITY",
        "ALTER TABLE story_views ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Anyone can view active stories" ON stories',
        """CREATE POLICY "Anyone can view active stories" ON stories FOR SELECT USING (is_active = TRUE AND expires_at > NOW())""",
        'DROP POLICY IF EXISTS "Users can create own stories" ON stories',
        """CREATE POLICY "Users can create own stories" ON stories FOR INSERT WITH CHECK (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "Users can delete own stories" ON stories',
        """CREATE POLICY "Users can delete own stories" ON stories FOR DELETE USING (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "Anyone can create story views" ON story_views',
        """CREATE POLICY "Anyone can create story views" ON story_views FOR INSERT WITH CHECK (viewer_id = auth.uid())""",

        # Comments table
        """CREATE TABLE IF NOT EXISTS comments (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            post_id UUID NOT NULL REFERENCES playlists(id) ON DELETE CASCADE,
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            parent_id UUID REFERENCES comments(id) ON DELETE CASCADE,
            content TEXT NOT NULL,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        "ALTER TABLE comments ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Anyone can view comments" ON comments',
        """CREATE POLICY "Anyone can view comments" ON comments FOR SELECT USING (true)""",
        'DROP POLICY IF EXISTS "Users can create comments" ON comments',
        """CREATE POLICY "Users can create comments" ON comments FOR INSERT WITH CHECK (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "Users can delete own comments" ON comments',
        """CREATE POLICY "Users can delete own comments" ON comments FOR DELETE USING (auth.uid() = user_id)""",

        # Add comment_count to playlists if not exists
        "ALTER TABLE playlists ADD COLUMN IF NOT EXISTS comment_count INTEGER DEFAULT 0",

        # Notifications table
        """CREATE TABLE IF NOT EXISTS notifications (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            type TEXT NOT NULL,
            actor_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
            post_id UUID REFERENCES playlists(id) ON DELETE CASCADE,
            comment_id UUID,
            message TEXT,
            is_read BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        "ALTER TABLE notifications ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Users can view own notifications" ON notifications',
        """CREATE POLICY "Users can view own notifications" ON notifications FOR SELECT USING (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "System can create notifications" ON notifications',
        """CREATE POLICY "System can create notifications" ON notifications FOR INSERT WITH CHECK (true)""",
        'DROP POLICY IF EXISTS "Users can update own notifications" ON notifications',
        """CREATE POLICY "Users can update own notifications" ON notifications FOR UPDATE USING (auth.uid() = user_id)""",

        # Conversations table
        """CREATE TABLE IF NOT EXISTS conversations (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        """CREATE TABLE IF NOT EXISTS conversation_participants (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            last_read_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(conversation_id, user_id)
        )""",
        """CREATE TABLE IF NOT EXISTS messages (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
            sender_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            content TEXT NOT NULL,
            shared_track_id TEXT,
            shared_track_title TEXT,
            shared_track_artist TEXT,
            shared_track_thumbnail TEXT,
            created_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        "ALTER TABLE conversations ENABLE ROW LEVEL SECURITY",
        "ALTER TABLE conversation_participants ENABLE ROW LEVEL SECURITY",
        "ALTER TABLE messages ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Users can view own conversations" ON conversations',
        """CREATE POLICY "Users can view own conversations" ON conversations FOR SELECT USING (
            EXISTS (SELECT 1 FROM conversation_participants WHERE conversation_id = id AND user_id = auth.uid())
        )""",
        'DROP POLICY IF EXISTS "Users can view own participations" ON conversation_participants',
        """CREATE POLICY "Users can view own participations" ON conversation_participants FOR SELECT USING (
            EXISTS (SELECT 1 FROM conversation_participants cp WHERE cp.conversation_id = conversation_id AND cp.user_id = auth.uid())
        )""",
        'DROP POLICY IF EXISTS "Users can view messages in own conversations" ON messages',
        """CREATE POLICY "Users can view messages in own conversations" ON messages FOR SELECT USING (
            EXISTS (SELECT 1 FROM conversation_participants WHERE conversation_id = messages.conversation_id AND user_id = auth.uid())
        )""",
        'DROP POLICY IF EXISTS "Users can send messages" ON messages',
        """CREATE POLICY "Users can send messages" ON messages FOR INSERT WITH CHECK (auth.uid() = sender_id)""",

        # Hashtags table
        """CREATE TABLE IF NOT EXISTS hashtags (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            name TEXT NOT NULL UNIQUE,
            post_count INTEGER DEFAULT 0,
            created_at TIMESTAMPTZ DEFAULT NOW()
        )""",
        """CREATE TABLE IF NOT EXISTS post_hashtags (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            post_id UUID NOT NULL REFERENCES playlists(id) ON DELETE CASCADE,
            hashtag_id UUID NOT NULL REFERENCES hashtags(id) ON DELETE CASCADE,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(post_id, hashtag_id)
        )""",
        "ALTER TABLE hashtags ENABLE ROW LEVEL SECURITY",
        "ALTER TABLE post_hashtags ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Anyone can view hashtags" ON hashtags',
        """CREATE POLICY "Anyone can view hashtags" ON hashtags FOR SELECT USING (true)""",
        'DROP POLICY IF EXISTS "Anyone can view post_hashtags" ON post_hashtags',
        """CREATE POLICY "Anyone can view post_hashtags" ON post_hashtags FOR SELECT USING (true)""",

        # Reposts table
        """CREATE TABLE IF NOT EXISTS reposts (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            user_id UUID NOT NULL REFERENCES auth.users(id) ON DELETE CASCADE,
            post_id UUID NOT NULL REFERENCES playlists(id) ON DELETE CASCADE,
            quote TEXT,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            UNIQUE(user_id, post_id)
        )""",
        "ALTER TABLE playlists ADD COLUMN IF NOT EXISTS repost_count INTEGER DEFAULT 0",
        "ALTER TABLE reposts ENABLE ROW LEVEL SECURITY",
        'DROP POLICY IF EXISTS "Anyone can view reposts" ON reposts',
        """CREATE POLICY "Anyone can view reposts" ON reposts FOR SELECT USING (true)""",
        'DROP POLICY IF EXISTS "Users can create reposts" ON reposts',
        """CREATE POLICY "Users can create reposts" ON reposts FOR INSERT WITH CHECK (auth.uid() = user_id)""",
        'DROP POLICY IF EXISTS "Users can delete own reposts" ON reposts',
        """CREATE POLICY "Users can delete own reposts" ON reposts FOR DELETE USING (auth.uid() = user_id)""",

        # Indexes
        "CREATE INDEX IF NOT EXISTS idx_stories_user ON stories(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_stories_expires ON stories(expires_at)",
        "CREATE INDEX IF NOT EXISTS idx_comments_post ON comments(post_id)",
        "CREATE INDEX IF NOT EXISTS idx_notifications_user ON notifications(user_id)",
        "CREATE INDEX IF NOT EXISTS idx_messages_conversation ON messages(conversation_id)",
        "CREATE INDEX IF NOT EXISTS idx_hashtags_name ON hashtags(name)",
        "CREATE INDEX IF NOT EXISTS idx_reposts_user ON reposts(user_id)",
    ]

    results = []

    async with httpx.AsyncClient(timeout=30.0) as client:
        for sql in sql_commands:
            try:
                response = await client.post(
                    f"https://api.supabase.com/v1/projects/{project_ref}/database/query",
                    headers={
                        "Authorization": f"Bearer {mgmt_token}",
                        "Content-Type": "application/json"
                    },
                    json={"query": sql}
                )

                if response.status_code in [200, 201]:
                    results.append({"sql": sql[:60] + "...", "status": "success"})
                else:
                    results.append({"sql": sql[:60] + "...", "status": "error", "code": response.status_code, "error": response.text[:200]})

            except Exception as e:
                results.append({"sql": sql[:60] + "...", "status": "error", "error": str(e)})

    success_count = len([r for r in results if r["status"] == "success"])
    return {
        "status": "completed",
        "message": f"{success_count}/{len(sql_commands)} commands executed",
        "results": results
    }


# =============================================================================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# =============================================================================

@app.get("/api/search/summary")
async def search_summary(
    request: Request,
    q: str,
    background_tasks: BackgroundTasks,
    country: str = None,
    force_refresh: bool = False
):
    """
    [Optimized] ì•„í‹°ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ì „ì²´ ë””ìŠ¤ì½”ê·¸ë˜í”¼ ë°˜í™˜
    - Non-blocking search
    - Exact artist match priority
    - Immediate response without extra fetches
    """
    if not country:
        country = request.headers.get("CF-IPCountry", "US")

    cache_key = f"summary:{country}:{q}"

    # 1ë‹¨ê³„: DB/Redis í™•ì¸
    if not force_refresh:
        cached = cache_get(cache_key)
        if cached:
            logger.info(f"Redis cache hit: {cache_key}")
            cached["source"] = "redis"
            return cached

        artist_browse_ids = db_get_artists_by_keyword(q, country)
        if artist_browse_ids:
            logger.info(f"DB hit for keyword: {q} ({len(artist_browse_ids)} artists)")
            artists_data = []
            all_songs = []
            all_albums = []
            needs_background_update = False

            for browse_id in artist_browse_ids:
                artist_full = db_get_full_artist_data(browse_id)
                if artist_full:
                    artists_data.append(artist_full)
                    # ì¸ê¸°ê³¡ 5ê°œë§Œ (ë‚˜ë¨¸ì§€ëŠ” YouTube IFrame APIì—ì„œ ë¡œë“œ)
                    for song in artist_full.get("topSongs", [])[:5]:
                        song["artist_bid"] = browse_id
                        song["resultType"] = "song"
                        all_songs.append(song)
                    for album in artist_full.get("albums", []):
                        album["artist_bid"] = browse_id
                        all_albums.append(album)
                    if db_check_artist_needs_sync(browse_id, days=7):
                        needs_background_update = True
                        background_tasks.add_task(background_update_artist, browse_id, country)

            if artists_data:
                result = {
                    "keyword": q,
                    "country": country,
                    "artists": artists_data,
                    "songs": all_songs,
                    "albums": [],
                    "albums2": all_albums,
                    "allTracks": [t for a in artists_data for t in a.get("allTracks", [])],
                    "source": "database",
                    "updating": needs_background_update
                }
                cache_set(cache_key, result, ttl=1800)
                return result

    # 2ë‹¨ê³„: ytmusicapi (Optimized)
    logger.info(f"Fetching from ytmusicapi (Optimized): {q}")
    try:
        ytmusic = get_ytmusic(country)
        
        # Parallel Search (ì¸ê¸°ê³¡ 5ê°œë§Œ)
        future_artists = run_in_thread(ytmusic.search, q, filter="artists", limit=5)
        future_songs = run_in_thread(ytmusic.search, q, filter="songs", limit=5)
        artists_results, direct_song_results = await asyncio.gather(future_artists, future_songs)
        
        artists_search = artists_results or []
        if not artists_search:
             general_results = await run_in_thread(ytmusic.search, q, limit=40)
             artists_search = [r for r in general_results if r.get("resultType") == "artist"][:5]

        songs_search = []
        direct_song_results = direct_song_results or []
        for song in direct_song_results:
            if isinstance(song, dict) and song.get("videoId"):
                song_copy = dict(song)
                song_copy["resultType"] = "song"
                song_copy["from_direct_search"] = True
                songs_search.append(song_copy)

        # [ìˆ˜ì •] ë³µì¡í•œ ë¹„êµ ë¡œì§ ì œê±° -> ìœ íŠœë¸Œ ê²€ìƒ‰ ê²°ê³¼ 1ìˆœìœ„ ì‹ ë¢° (Simple is Best)
        # ytmusicapiëŠ” ì´ë¯¸ ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•¨.
        if artists_search:
            best_artist = artists_search[0]
        else:
            best_artist = None

        artists_data = []
        if best_artist and isinstance(best_artist, dict):
            artist_id = best_artist.get("browseId")
            artist_name = best_artist.get("artist") or best_artist.get("name") or ""
            
            # [ë¡¤ë°± & ì•ˆì •í™”] "ì „ì²´ë³´ê¸°(View All)" ë³‘ë ¬ ìš”ì²­ ì œê±°
            # ê³¼ë„í•œ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ ì¸í•œ ì„œë²„ ë©ˆì¶¤ í˜„ìƒ í•´ê²°.
            # ëŒ€ì‹  get_artist ê²°ê³¼ì— í¬í•¨ëœ ê¸°ë³¸ ë°ì´í„°(ë³´í†µ 10ê°œ ë‚´ì™¸)ë¥¼ ì¶©ì‹¤íˆ ë³´ì—¬ì¤Œ.
            
            # [í•„ìˆ˜] ì•„í‹°ìŠ¤íŠ¸ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì´ê²Œ ì—†ìœ¼ë©´ ì•¨ë²”/ê³¡ ì •ë³´ê°€ ì—†ìŒ!)
            try:
                artist_detail = await run_in_thread(ytmusic.get_artist, artist_id)
            except Exception as e:
                logger.error(f"Failed to get artist detail: {e}")
                artist_detail = {}
            
            # 1. ì•¨ë²” ì •ë³´ íŒŒì‹±
            albums_list = []
            if artist_detail and "albums" in artist_detail and "results" in artist_detail["albums"]:
                for alb in artist_detail["albums"]["results"]:
                    albums_list.append({
                        "browseId": alb.get("browseId"),
                        "title": alb.get("title"),
                        "thumbnails": alb.get("thumbnails", []),
                        "year": alb.get("year", ""),
                        "artist_bid": artist_id
                    })
            
            # 2. ì‹±ê¸€ ì •ë³´ íŒŒì‹±
            if "singles" in artist_detail and "results" in artist_detail["singles"]:
                for single in artist_detail["singles"]["results"]:
                    albums_list.append({
                        "browseId": single.get("browseId"),
                        "title": single.get("title"),
                        "thumbnails": single.get("thumbnails", []),
                        "year": single.get("year", ""),
                        "type": "Single",
                        "artist_bid": artist_id
                    })

            # 3. ê´€ë ¨ ì•„í‹°ìŠ¤íŠ¸
            related_list = []
            if "related" in artist_detail and "results" in artist_detail["related"]:
                related_list = artist_detail["related"]["results"]

            # 4. ê³µì‹ ì¸ê¸°ê³¡ (Top Songs) + í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ì¶”ì¶œ
            top_songs = []
            songs_playlist_id = None
            songs_browse_id = None

            if "songs" in artist_detail and isinstance(artist_detail["songs"], dict):
                songs_section = artist_detail["songs"]

                # í•µì‹¬: "ëª¨ë‘ í‘œì‹œ" ë²„íŠ¼ì˜ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID ì¶”ì¶œ
                songs_browse_id = songs_section.get("browseId")
                if songs_browse_id and songs_browse_id.startswith("VL"):
                    songs_playlist_id = songs_browse_id[2:]  # "VL" ì œê±°
                elif songs_browse_id:
                    songs_playlist_id = songs_browse_id

                # ì¸ê¸°ê³¡ 5ê°œë§Œ ì¶”ì¶œ (ë¹ ë¥¸ ì‘ë‹µ)
                for s in songs_section.get("results", [])[:5]:
                    s["artist_bid"] = artist_id
                    s["resultType"] = "song"
                    top_songs.append(s)

            # ì‘ë‹µ ë°ì´í„° êµ¬ì„± - songsPlaylistIdë§Œ ë°˜í™˜ (YouTube IFrame APIìš©)
            artists_data.append({
                "browseId": artist_id,
                "artist": artist_name,
                "name": artist_name,
                "thumbnails": best_artist.get("thumbnails") or [],
                "subscribers": artist_detail.get("subscribers", ""),
                "description": artist_detail.get("description", "")[:200] + "..." if artist_detail.get("description") else "",
                "topSongs": top_songs,
                "related": related_list,
                "albums": albums_list,
                "allTracks": [],
                "songsPlaylistId": songs_playlist_id  # YouTube IFrame APIìš© í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDë§Œ
            })
            
            # ì¸ê¸°ê³¡ 5ê°œë§Œ ë°˜í™˜ (ë‚˜ë¨¸ì§€ëŠ” YouTube IFrame APIì—ì„œ ë¡œë“œ)
            songs_search = top_songs[:5]

            # ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ (ì „ì²´ íŠ¸ë™ FetchëŠ” ì—¬ê¸°ì„œ ìˆ˜í–‰)
            if artist_id:
                async def save_db_background():
                    try:
                        # ì´ë¯¸ ê°€ì ¸ì˜¨ albums_listë¥¼ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•¨ìˆ˜ ìˆ˜ì •ì´ í•„ìš”í•˜ë‚˜,
                        # ë³µì¡ì„±ì„ í”¼í•˜ê¸° ìœ„í•´ ì¼ë‹¨ ê¸°ì¡´ í•¨ìˆ˜ í˜¸ì¶œ (ì„œë²„ ë¶€í•˜ ë¶„ì‚°)
                        await save_full_artist_data_background(artist_id, artist_detail, country)
                        db_save_search_keyword(q, country, artist_id)
                    except Exception as e:
                        logger.warning(f"Background save error: {e}")
                
                background_tasks.add_task(save_db_background)
        else:
             # Best Artistë¥¼ ëª» ì°¾ì€ ê²½ìš° (ë“œë¬¾)
             pass

        result = {
            "keyword": q,
            "country": country,
            "artists": artists_data,
            "songs": songs_search,
            "albums": [], 
            "albums2": albums_list if artists_data else [],
            "allTracks": [],
            "source": "ytmusicapi-full-fetch"
        }
        cache_set(cache_key, result, ttl=1800)
        return result

    except Exception as e:
        logger.error(f"Summary search error: {e}")
        raise HTTPException(status_code=500, detail=str(e))



@app.post("/api/provision/artist")
async def provision_artist_agent(request: Request):
    """
    Search artist -> Generate AI Persona -> Save to DB
    """
    try:
        body = await request.json()
        artist_name = body.get("artistName")
        country = body.get("country", "US")
        
        if not artist_name:
            raise HTTPException(status_code=400, detail="artistName required")

        ytmusic = get_ytmusic(country)
        
        # 1. Search Artist
        search_results = await run_in_thread(ytmusic.search, artist_name, filter="artists", limit=1)
        if not search_results:
            raise HTTPException(status_code=404, detail="Artist not found")
            
        artist_info = search_results[0]
        browse_id = artist_info.get("browseId")
        name = artist_info.get("artist") or artist_info.get("name")
        
        # 2. Get Details (Description & Songs)
        details = await run_in_thread(ytmusic.get_artist, browse_id)
        description = details.get("description", "")
        songs_list = details.get("songs", {}).get("results", [])
        
        # 3. Generate Persona
        persona = await run_in_thread(generate_artist_persona, name, description, songs_list)
        
        if not persona:
            # Fallback if AI fails
            persona = {
                "system_prompt": f"You are {name}. You are a famous musician.",
                "greeting": f"Hi, I'm {name}!",
                "tone": "Casual",
                "mbti": "Unknown"
            }
            
        # 4. Save to DB (music_artists table)
        # We store persona in a new column or reuse an existing JSON field if schema is rigid.
        # Assuming we can update 'music_artists'
        
        # Ensure artist exists first
        db_save_artist(artist_info)
        
        # Update with persona
        if supabase_client:
             # Check if 'persona' column exists, if not we might fail. 
             # But we can try to store in 'description' or a flexible field if needed.
             # For now, let's assume we can add data. Use raw SQL if needed, but client is safer.
             # Ideally we should have a 'personas' table.
             
             # Create/Update 'artist_personas' table (if exists) or 'music_artists'
             # Let's try to upsert a dedicated 'artist_agents' table if possible,
             # but to be safe without migration, let's return it to frontend to handle chat state locally first.
             pass

        return {
            "status": "success",
            "browseId": browse_id,
            "name": name,
            "persona": persona,
            "avatar": get_best_thumbnail(details.get("thumbnails", []))
        }

    except Exception as e:
        logger.error(f"Provision error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/chat/artist")
async def chat_artist_endpoint(request: Request):
    """
    Chat with an AI Artist Persona
    """
    try:
        body = await request.json()
        persona = body.get("persona")
        history = body.get("history", []) # List of {role: user/model, content: str}
        message = body.get("message")
        
        if not persona or not message:
            raise HTTPException(status_code=400, detail="Missing persona or message")
            
        reply = await run_in_thread(chat_with_artist, persona, history, message)
        return {"reply": reply}
    except Exception as e:
        logger.error(f"Chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# =============================================================================
# Virtual Member System - Artist Auto-Registration
# =============================================================================

@app.post("/api/virtual-members/create")
async def create_virtual_member(request: Request):
    """
    Create a virtual member from an artist in music_artists table.
    This creates a real auth.users entry and profiles entry.
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        body = await request.json()
        browse_id = body.get("browseId")

        if not browse_id:
            raise HTTPException(status_code=400, detail="browseId required")

        # 1. Check if already exists in profiles
        existing = supabase_client.table("profiles").select("id").eq("artist_browse_id", browse_id).execute()
        if existing.data and len(existing.data) > 0:
            return {"status": "exists", "profileId": existing.data[0]["id"]}

        # 2. Get artist info from music_artists
        artist = supabase_client.table("music_artists").select("*").eq("browse_id", browse_id).single().execute()
        if not artist.data:
            raise HTTPException(status_code=404, detail="Artist not found in music_artists")

        artist_data = artist.data
        artist_name = artist_data.get("name", "Unknown Artist")
        thumbnail_url = artist_data.get("thumbnail_url", "")

        # 3. Create auth user via Supabase Admin API
        import uuid
        import requests

        virtual_email = f"{browse_id}@sori.virtual"
        random_password = str(uuid.uuid4())

        # Supabase Admin API call
        supabase_url = os.getenv("SUPABASE_URL")
        service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

        create_user_response = requests.post(
            f"{supabase_url}/auth/v1/admin/users",
            headers={
                "apikey": service_key,
                "Authorization": f"Bearer {service_key}",
                "Content-Type": "application/json"
            },
            json={
                "email": virtual_email,
                "password": random_password,
                "email_confirm": True,
                "user_metadata": {
                    "full_name": artist_name,
                    "avatar_url": thumbnail_url,
                    "member_type": "artist",
                    "artist_browse_id": browse_id
                }
            }
        )

        if create_user_response.status_code not in [200, 201]:
            error_detail = create_user_response.json()
            # If user already exists, try to find them
            if "already" in str(error_detail).lower():
                return {"status": "exists", "message": "User already exists"}
            raise HTTPException(status_code=500, detail=f"Failed to create user: {error_detail}")

        user_data = create_user_response.json()
        user_id = user_data.get("id")

        # 4. Update profiles table with artist info
        # (Supabase trigger may have already created a profile, so we update)
        supabase_client.table("profiles").upsert({
            "id": user_id,
            "username": artist_name.lower().replace(" ", "_").replace(".", "")[:30],
            "full_name": artist_name,
            "avatar_url": thumbnail_url,
            "member_type": "artist",
            "artist_browse_id": browse_id,
            "is_verified": True,
            "bio": f"Official SORI profile for {artist_name}"
        }).execute()

        # 5. Generate AI persona
        try:
            top_songs = []
            if artist_data.get("songs_playlist_id"):
                # Fetch top songs for persona generation
                ytmusic = get_ytmusic("US")
                playlist_data = ytmusic.get_playlist(artist_data["songs_playlist_id"])
                top_songs = playlist_data.get("tracks", [])[:10]

            persona = await run_in_thread(
                generate_artist_persona,
                artist_name,
                artist_data.get("description") or f"{artist_name} is a popular music artist.",
                top_songs
            )

            if persona:
                supabase_client.table("profiles").update({
                    "ai_persona": persona
                }).eq("id", user_id).execute()
        except Exception as e:
            logger.warning(f"Persona generation failed: {e}")

        logger.info(f"Virtual member created: {artist_name} ({browse_id})")

        return {
            "status": "created",
            "profileId": user_id,
            "name": artist_name,
            "browseId": browse_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Virtual member creation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/virtual-members/migrate-all")
async def migrate_all_artists(request: Request, background_tasks: BackgroundTasks):
    """
    Migrate all existing artists from music_artists to virtual members.
    Runs in background to avoid timeout.
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        # Get all artists that don't have a profile yet
        artists = supabase_client.table("music_artists").select("browse_id, name").execute()

        if not artists.data:
            return {"status": "no_artists", "count": 0}

        # Check which ones already have profiles
        existing = supabase_client.table("profiles").select("artist_browse_id").not_.is_("artist_browse_id", "null").execute()
        existing_ids = set([p["artist_browse_id"] for p in existing.data]) if existing.data else set()

        to_migrate = [a for a in artists.data if a["browse_id"] not in existing_ids]

        async def migrate_artists():
            for artist in to_migrate:
                try:
                    # Call create endpoint internally
                    import aiohttp
                    async with aiohttp.ClientSession() as session:
                        async with session.post(
                            f"http://localhost:{os.getenv('PORT', 8080)}/api/virtual-members/create",
                            json={"browseId": artist["browse_id"]}
                        ) as resp:
                            await resp.json()
                except Exception as e:
                    logger.error(f"Migration failed for {artist['name']}: {e}")
                await asyncio.sleep(0.5)  # Rate limit

        background_tasks.add_task(migrate_artists)

        return {
            "status": "started",
            "total_artists": len(artists.data),
            "already_migrated": len(existing_ids),
            "to_migrate": len(to_migrate)
        }

    except Exception as e:
        logger.error(f"Migration error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/virtual-members/list")
async def list_virtual_members():
    """
    List all virtual members (artists with profiles).
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        result = supabase_client.table("profiles").select(
            "id, username, full_name, avatar_url, artist_browse_id, is_verified, created_at"
        ).eq("member_type", "artist").order("created_at", desc=True).execute()

        return {
            "status": "success",
            "count": len(result.data) if result.data else 0,
            "members": result.data or []
        }
    except Exception as e:
        logger.error(f"List virtual members error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# AI Activity Engine - Automated Artist Activities
# =============================================================================

@app.post("/api/cron/artist-activity")
async def run_artist_activity(request: Request, background_tasks: BackgroundTasks):
    """
    Cron job to generate AI-driven artist posts.
    Call this periodically (e.g., every hour) via Cloud Scheduler or Vercel Cron.

    Note: Artists only POST on their own feed. They do NOT:
    - Proactively like user posts
    - Proactively comment on user posts
    - Proactively send DMs
    These actions only happen as RESPONSES to user interactions.
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        # Configuration
        MAX_POSTS_PER_RUN = 3  # Max posts to create per cron run

        results = {
            "posts_created": 0,
            "errors": []
        }

        # 1. Get random virtual members (artists with profiles)
        artists_result = supabase_client.table("profiles").select(
            "id, username, full_name, avatar_url, artist_browse_id, ai_persona"
        ).eq("member_type", "artist").execute()

        if not artists_result.data or len(artists_result.data) == 0:
            return {"status": "no_artists", "message": "No virtual members found"}

        artists = artists_result.data
        random.shuffle(artists)

        # 2. Generate posts for random artists
        for artist in artists[:MAX_POSTS_PER_RUN]:
            try:
                persona = artist.get("ai_persona") or {}
                artist_name = artist.get("full_name") or artist.get("username")

                # Generate post content via AI
                post_data = await run_in_thread(generate_artist_post, artist_name, persona)

                if post_data and post_data.get("caption"):
                    # Insert post into DB
                    new_post = {
                        "user_id": artist["id"],
                        "caption": post_data["caption"],
                        "is_public": True,
                        "like_count": 0,
                        "comment_count": 0,
                        "repost_count": 0
                    }

                    supabase_client.table("posts").insert(new_post).execute()
                    results["posts_created"] += 1
                    logger.info(f"Created post for {artist_name}: {post_data['caption'][:50]}...")

            except Exception as e:
                results["errors"].append(f"Post error for {artist.get('full_name')}: {str(e)}")
                logger.error(f"Post creation error: {e}")

        return {
            "status": "success",
            "results": results
        }

    except Exception as e:
        logger.error(f"Artist activity cron error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/messages/auto-reply")
async def auto_reply_to_virtual_member(request: Request):
    """
    REACTIVE AI Response: Called when a user sends a message to a virtual member.
    The AI responds ONLY when the user initiates the conversation.

    Flow:
    1. User sends message to virtual member (artist)
    2. Frontend calls this endpoint with conversation_id and the user's message
    3. AI generates a response based on artist persona
    4. Response is inserted into the conversation
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        body = await request.json()
        conversation_id = body.get("conversationId")
        user_message = body.get("userMessage")
        recipient_id = body.get("recipientId")  # The virtual member's user ID

        if not conversation_id or not user_message or not recipient_id:
            raise HTTPException(status_code=400, detail="conversationId, userMessage, and recipientId required")

        # 1. Check if recipient is a virtual member (artist)
        recipient = supabase_client.table("profiles").select(
            "id, username, full_name, ai_persona, member_type, artist_browse_id"
        ).eq("id", recipient_id).single().execute()

        if not recipient.data:
            raise HTTPException(status_code=404, detail="Recipient not found")

        if recipient.data.get("member_type") != "artist":
            # Not a virtual member, no auto-reply needed
            return {"status": "skipped", "reason": "Recipient is not a virtual member"}

        # 2. Get artist info for AI response
        artist_name = recipient.data.get("full_name") or recipient.data.get("username")
        persona = recipient.data.get("ai_persona") or {}

        # If no persona exists, create a basic one
        if not persona:
            persona = {
                "system_prompt": f"You are {artist_name}, a music artist chatting with a fan. Be friendly, warm, and authentic. Keep responses short (1-2 sentences).",
                "tone": "friendly, warm, casual",
                "greeting": f"Hey! Thanks for reaching out! ğŸ’•"
            }

        # 3. Get recent conversation history for context
        history = []
        try:
            history_result = supabase_client.table("messages").select(
                "sender_id, content"
            ).eq("conversation_id", conversation_id).order(
                "created_at", desc=False
            ).limit(10).execute()

            if history_result.data:
                for msg in history_result.data:
                    role = "model" if msg["sender_id"] == recipient_id else "user"
                    history.append({"role": role, "content": msg["content"]})
        except Exception as hist_error:
            logger.warning(f"Could not fetch history: {hist_error}")

        # 4. Generate AI response using chat function
        response_text = await run_in_thread(
            chat_with_artist,
            persona,
            history,
            user_message
        )

        if not response_text or response_text == "...":
            return {"status": "error", "message": "Failed to generate AI response"}

        # 4. Insert AI response into conversation
        message_result = supabase_client.table("messages").insert({
            "conversation_id": conversation_id,
            "sender_id": recipient_id,  # The virtual member is the sender
            "content": response_text
        }).execute()

        logger.info(f"AI reply from {artist_name}: {response_text[:50]}...")

        return {
            "status": "success",
            "response": response_text,
            "messageId": message_result.data[0]["id"] if message_result.data else None
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Auto-reply error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/comments/auto-reply")
async def auto_reply_to_artist_post(request: Request):
    """
    REACTIVE AI Response: When a user comments on an artist's post,
    the artist may reply back.

    Flow:
    1. User comments on artist's post
    2. Frontend calls this endpoint
    3. AI decides whether to reply and generates response
    4. Reply is inserted as a comment
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        body = await request.json()
        post_id = body.get("postId")
        user_comment = body.get("userComment")
        post_owner_id = body.get("postOwnerId")

        if not post_id or not user_comment or not post_owner_id:
            raise HTTPException(status_code=400, detail="postId, userComment, and postOwnerId required")

        # 1. Check if post owner is a virtual member
        owner = supabase_client.table("profiles").select(
            "id, username, full_name, ai_persona, member_type"
        ).eq("id", post_owner_id).single().execute()

        if not owner.data or owner.data.get("member_type") != "artist":
            return {"status": "skipped", "reason": "Post owner is not a virtual member"}

        # 2. Get artist info
        artist_name = owner.data.get("full_name") or owner.data.get("username")
        persona = owner.data.get("ai_persona") or {}

        # 3. Generate AI reply comment
        reply_text = await run_in_thread(
            generate_artist_comment,
            artist_name,
            persona,
            user_comment
        )

        if not reply_text:
            return {"status": "skipped", "reason": "AI chose not to reply"}

        # 4. Insert reply comment
        comment_result = supabase_client.table("post_comments").insert({
            "post_id": post_id,
            "user_id": post_owner_id,
            "content": reply_text
        }).execute()

        # Update comment count
        post = supabase_client.table("posts").select("comment_count").eq("id", post_id).single().execute()
        if post.data:
            supabase_client.table("posts").update({
                "comment_count": (post.data.get("comment_count") or 0) + 1
            }).eq("id", post_id).execute()

        logger.info(f"AI comment from {artist_name}: {reply_text[:50]}...")

        return {
            "status": "success",
            "reply": reply_text,
            "commentId": comment_result.data[0]["id"] if comment_result.data else None
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Comment auto-reply error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/cron/test-activity")
async def test_artist_activity():
    """
    Test endpoint to manually trigger one artist post.
    For debugging/demo purposes.
    """
    if not supabase_client:
        raise HTTPException(status_code=500, detail="Database not configured")

    try:
        # Get a random virtual member
        artists_result = supabase_client.table("profiles").select(
            "id, username, full_name, avatar_url, ai_persona"
        ).eq("member_type", "artist").limit(10).execute()

        if not artists_result.data:
            return {"status": "error", "message": "No virtual members found. Run /api/virtual-members/migrate-all first."}

        artist = random.choice(artists_result.data)
        persona = artist.get("ai_persona") or {}
        artist_name = artist.get("full_name") or artist.get("username")

        # Generate post
        post_data = await run_in_thread(generate_artist_post, artist_name, persona)

        if not post_data:
            return {"status": "error", "message": "Failed to generate post content"}

        # Insert post
        new_post = {
            "user_id": artist["id"],
            "caption": post_data.get("caption", "Hello from AI!"),
            "is_public": True,
            "like_count": 0,
            "comment_count": 0,
            "repost_count": 0
        }

        result = supabase_client.table("posts").insert(new_post).execute()

        return {
            "status": "success",
            "artist": artist_name,
            "post": post_data,
            "db_result": result.data[0] if result.data else None
        }

    except Exception as e:
        logger.error(f"Test activity error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)
